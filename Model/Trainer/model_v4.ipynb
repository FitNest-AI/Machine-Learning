{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Commands\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'left_eye': 1,\n",
    "    'right_eye': 2,\n",
    "    'left_ear': 3,\n",
    "    'right_ear': 4,\n",
    "    'left_shoulder': 5,\n",
    "    'right_shoulder': 6,\n",
    "    'left_elbow': 7,\n",
    "    'right_elbow': 8,\n",
    "    'left_wrist': 9,\n",
    "    'right_wrist': 10,\n",
    "    'left_hip': 11,\n",
    "    'right_hip': 12,\n",
    "    'left_knee': 13,\n",
    "    'right_knee': 14,\n",
    "    'left_ankle': 15,\n",
    "    'right_ankle': 16\n",
    "}\n",
    "\n",
    "# Maps bones to a matplotlib color name.\n",
    "KEYPOINT_EDGE_INDS_TO_COLOR = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "def _keypoints_and_edges_for_display(keypoints_with_scores,\n",
    "                                     height,\n",
    "                                     width,\n",
    "                                     keypoint_threshold=0.11):\n",
    "\n",
    "  keypoints_all = []\n",
    "  keypoint_edges_all = []\n",
    "  edge_colors = []\n",
    "  num_instances, _, _, _ = keypoints_with_scores.shape\n",
    "  for idx in range(num_instances):\n",
    "    kpts_x = keypoints_with_scores[0, idx, :, 1]\n",
    "    kpts_y = keypoints_with_scores[0, idx, :, 0]\n",
    "    kpts_scores = keypoints_with_scores[0, idx, :, 2]\n",
    "    kpts_absolute_xy = np.stack(\n",
    "        [width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n",
    "    kpts_above_thresh_absolute = kpts_absolute_xy[\n",
    "        kpts_scores > keypoint_threshold, :]\n",
    "    keypoints_all.append(kpts_above_thresh_absolute)\n",
    "\n",
    "    for edge_pair, color in KEYPOINT_EDGE_INDS_TO_COLOR.items():\n",
    "      if (kpts_scores[edge_pair[0]] > keypoint_threshold and\n",
    "          kpts_scores[edge_pair[1]] > keypoint_threshold):\n",
    "        x_start = kpts_absolute_xy[edge_pair[0], 0]\n",
    "        y_start = kpts_absolute_xy[edge_pair[0], 1]\n",
    "        x_end = kpts_absolute_xy[edge_pair[1], 0]\n",
    "        y_end = kpts_absolute_xy[edge_pair[1], 1]\n",
    "        line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "        keypoint_edges_all.append(line_seg)\n",
    "        edge_colors.append(color)\n",
    "  if keypoints_all:\n",
    "    keypoints_xy = np.concatenate(keypoints_all, axis=0)\n",
    "  else:\n",
    "    keypoints_xy = np.zeros((0, 17, 2))\n",
    "\n",
    "  if keypoint_edges_all:\n",
    "    edges_xy = np.stack(keypoint_edges_all, axis=0)\n",
    "  else:\n",
    "    edges_xy = np.zeros((0, 2, 2))\n",
    "  return keypoints_xy, edges_xy, edge_colors\n",
    "\n",
    "\n",
    "def draw_prediction_on_image(\n",
    "    image, keypoints_with_scores, crop_region=None, close_figure=False,\n",
    "    output_image_height=None):\n",
    "\n",
    "  height, width, channel = image.shape\n",
    "  aspect_ratio = float(width) / height\n",
    "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "  # To remove the huge white borders\n",
    "  fig.tight_layout(pad=0)\n",
    "  ax.margins(0)\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_xticklabels([])\n",
    "  plt.axis('off')\n",
    "\n",
    "  im = ax.imshow(image)\n",
    "  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
    "  ax.add_collection(line_segments)\n",
    "  # Turn off tick labels\n",
    "  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
    "\n",
    "  (keypoint_locs, keypoint_edges,\n",
    "   edge_colors) = _keypoints_and_edges_for_display(\n",
    "       keypoints_with_scores, height, width)\n",
    "\n",
    "  line_segments.set_segments(keypoint_edges)\n",
    "  line_segments.set_color(edge_colors)\n",
    "  if keypoint_edges.shape[0]:\n",
    "    line_segments.set_segments(keypoint_edges)\n",
    "    line_segments.set_color(edge_colors)\n",
    "  if keypoint_locs.shape[0]:\n",
    "    scat.set_offsets(keypoint_locs)\n",
    "\n",
    "  if crop_region is not None:\n",
    "    xmin = max(crop_region['x_min'] * width, 0.0)\n",
    "    ymin = max(crop_region['y_min'] * height, 0.0)\n",
    "    rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n",
    "    rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n",
    "    rect = patches.Rectangle(\n",
    "        (xmin,ymin),rec_width,rec_height,\n",
    "        linewidth=1,edgecolor='b',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "  fig.canvas.draw()\n",
    "  image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "  image_from_plot = image_from_plot.reshape(\n",
    "      fig.canvas.get_width_height()[::-1] + (3,))\n",
    "  plt.close(fig)\n",
    "  if output_image_height is not None:\n",
    "    output_image_width = int(output_image_height / height * width)\n",
    "    image_from_plot = cv2.resize(\n",
    "        image_from_plot, dsize=(output_image_width, output_image_height),\n",
    "         interpolation=cv2.INTER_CUBIC)\n",
    "  return image_from_plot\n",
    "\n",
    "# def to_gif(images, duration):\n",
    "#   \"\"\"Converts image sequence (4D numpy array) to gif.\"\"\"\n",
    "#   imageio.mimsave('./animation.gif', images, duration=duration)\n",
    "#   return embed.embed_file('./animation.gif')\n",
    "\n",
    "def progress(value, max=100):\n",
    "  return HTML(\"\"\"\n",
    "      <progress\n",
    "          value='{value}'\n",
    "          max='{max}',\n",
    "          style='width: 100%'\n",
    "      >\n",
    "          {value}\n",
    "      </progress>\n",
    "  \"\"\".format(value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonDetector:\n",
    "    def __init__(self):\n",
    "        model_path = \"https://www.kaggle.com/models/google/movenet/frameworks/TensorFlow2/variations/singlepose-thunder/versions/4\"\n",
    "        self.movenet = self.load_model(model_path)\n",
    "    \n",
    "    def load_model(self,model_path):\n",
    "        model = hub.load(model_path)\n",
    "        movenet = model.signatures['serving_default']\n",
    "        return movenet\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.movenet\n",
    "    \n",
    "    def detect(self,input_image,inference_count=3):\n",
    "        input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "        outputs = self.movenet(input_image)\n",
    "        keypoints_with_scores = outputs['output_0'].numpy()\n",
    "        return keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def process_image(self,image_path):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.compat.v1.image.decode_jpeg(image)\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        image = tf.cast(tf.image.resize_with_pad(image, 256, 256), dtype=tf.int32)\n",
    "        return image\n",
    "    \n",
    "    def augment_image(self,image):\n",
    "        image = tf.image.random_brightness(image, max_delta=0.3)\n",
    "        image = tf.image.random_contrast(image, lower=0.2, upper=0.5)\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        return image\n",
    "    \n",
    "    def display_image(self,image):\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image[0])\n",
    "        plt.show()\n",
    "        \n",
    "    def display_image_with_keypoints(self,image,keypoints):\n",
    "        display_image = tf.cast(tf.image.resize_with_pad(\n",
    "            image, 1280, 1280), dtype=tf.int32)\n",
    "        output_overlay = draw_prediction_on_image(\n",
    "            np.squeeze(display_image.numpy(), axis=0), keypoints)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(output_overlay)\n",
    "        _ = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detector = PersonDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageProcessor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(detector:PersonDetector,imageProcessor:ImageProcessor,path:str):\n",
    "    keypoint_data = []\n",
    "    image_label = []\n",
    "    for images in os.listdir(path):\n",
    "        image = imageProcessor.process_image(os.path.join(path,images))\n",
    "        keypoints = detector.detect(image)\n",
    "        \n",
    "        # key = keypoints[0][0]\n",
    "        \n",
    "        keypoint_data.append(np.ndarray.flatten(keypoints[0][0]))\n",
    "        image_label.append(path.split('/')[-2])\n",
    "    \n",
    "    #     angle = calculate_angle(key)\n",
    "    #     angle_data.append(angle)\n",
    "\n",
    "    # angle_data = np.array(angle_data)\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    result[\"data\"] = keypoint_data\n",
    "    result[\"label\"] = image_label\n",
    "    # result[\"right knee\"] = angle_data.T[0]\n",
    "    # result[\"left knee\"] = angle_data.T[1]\n",
    "    # result[\"right hip\"] = angle_data.T[2]\n",
    "    # result[\"left hip\"] = angle_data.T[3]\n",
    "    # result[\"right elbow\"] = angle_data.T[4]\n",
    "    # result[\"left elbow\"] = angle_data.T[5]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# def calculate_angle(key):\n",
    "    \n",
    "#     right_wrist = key[10]\n",
    "#     left_wrist = key[9]\n",
    "    \n",
    "#     right_elbow = key[8]\n",
    "#     left_elbow = key[7]\n",
    "    \n",
    "#     right_shoulder = key[6]\n",
    "#     left_shoulder = key[5]\n",
    "    \n",
    "#     right_hip = key[12]\n",
    "#     left_hip = key[11]\n",
    "    \n",
    "#     right_knee = key[14]\n",
    "#     left_knee = key[13]\n",
    "    \n",
    "#     right_ankle = key[16]\n",
    "#     left_ankle = key[15]\n",
    "    \n",
    "#     angle_right_we = np.degrees(np.arctan2(right_wrist[1] - right_elbow[1], right_wrist[0] - right_elbow[0]))\n",
    "#     angle_right_es = np.degrees(np.arctan2(right_elbow[1] - right_shoulder[1], right_elbow[0] - right_shoulder[0]))\n",
    "#     angle_right_sh = np.degrees(np.arctan2(right_shoulder[1] - right_hip[1], right_shoulder[0] - right_hip[0]))\n",
    "#     angle_right_hk = np.degrees(np.arctan2(right_hip[1] - right_knee[1], right_hip[0] - right_knee[0]))\n",
    "#     angle_right_ka = np.degrees(np.arctan2(right_knee[1] - right_ankle[1], right_knee[0] - right_ankle[0]))\n",
    "    \n",
    "#     angle_left_we = np.degrees(np.arctan2(left_wrist[1] - left_elbow[1], left_wrist[0] - left_elbow[0]))\n",
    "#     angle_left_es = np.degrees(np.arctan2(left_elbow[1] - left_shoulder[1], left_elbow[0] - left_shoulder[0]))\n",
    "#     angle_left_sh = np.degrees(np.arctan2(left_shoulder[1] - left_hip[1], left_shoulder[0] - left_hip[0]))\n",
    "#     angle_left_hk = np.degrees(np.arctan2(left_hip[1] - left_knee[1], left_hip[0] - left_knee[0]))\n",
    "#     angle_left_ka = np.degrees(np.arctan2(left_knee[1] - left_ankle[1], left_knee[0] - left_ankle[0]))\n",
    "    \n",
    "#     angles = [angle_right_we,angle_right_es,angle_right_sh,angle_right_hk,angle_right_ka,angle_left_we,angle_left_es,angle_left_sh,angle_left_hk,angle_left_ka]\n",
    "#     angles = [angle if angle > 0 else angle + 180 for angle in angles]\n",
    "    \n",
    "#     right_knee_angle = abs(angles[3] - angles[4])\n",
    "#     left_knee_angle = abs(angles[8] - angles[9])\n",
    "    \n",
    "#     right_hip_angle = abs(angles[2] - angles[3])\n",
    "#     left_hip_angle = abs(angles[7] - angles[8])\n",
    "    \n",
    "#     right_elbow_angle = abs(angles[0] - angles[1])\n",
    "#     left_elbow_angle = abs(angles[5] - angles[6])\n",
    "    \n",
    "#     angles = [right_knee_angle,left_knee_angle,right_hip_angle,left_hip_angle,right_elbow_angle,left_elbow_angle]\n",
    "    \n",
    "#     return angles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing barbell biceps curl\n",
      "Saving barbell biceps curl\n",
      "Processing hammer curl\n",
      "Saving hammer curl\n",
      "Processing hip thrust\n",
      "Saving hip thrust\n",
      "Processing lateral raises\n",
      "Saving lateral raises\n",
      "Processing leg raises\n",
      "Saving leg raises\n",
      "Processing pull up\n",
      "Saving pull up\n",
      "Processing pushup\n",
      "Saving pushup\n",
      "Processing russian twist\n",
      "Saving russian twist\n",
      "Processing situp\n",
      "Saving situp\n",
      "Processing squat\n",
      "Saving squat\n",
      "Processing standingFront\n",
      "Saving standingFront\n",
      "Processing standingSide\n",
      "Saving standingSide\n",
      "Processing tricep dips\n",
      "Saving tricep dips\n",
      "Processing tricep pushdown\n",
      "Saving tricep pushdown\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Datasets/Trainer/processed/\"\n",
    "for folders in os.listdir(path):\n",
    "    print(f'Processing {folders}')\n",
    "    result = load_image(detector,imageProcessor,os.path.join(path,folders))\n",
    "    print(f'Saving {folders}')\n",
    "    result.to_csv(f\"../../Datasets/Trainer/csv_raw/{folders}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../Datasets/Trainer/csv_raw/\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for csv_file in os.listdir(path):\n",
    "    df = pd.read_csv(os.path.join(path,csv_file))\n",
    "    df[\"label\"] = csv_file.split('.')[0]\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs,axis=0)\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(df[\"data\"],df[\"label\"],test_size=0.1)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1)\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "train_df[\"data\"] = x_train\n",
    "train_df[\"label\"] = y_train\n",
    "\n",
    "val_df = pd.DataFrame()\n",
    "val_df[\"data\"] = x_val\n",
    "val_df[\"label\"] = y_val\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"data\"] = x_test\n",
    "test_df[\"label\"] = y_test\n",
    "\n",
    "\n",
    "train_df.to_csv(\"../../Datasets/Trainer/csv_processed/train.csv\",index=False)\n",
    "val_df.to_csv(\"../../Datasets/Trainer/csv_processed/val.csv\",index=False)\n",
    "test_df.to_csv(\"../../Datasets/Trainer/csv_processed/test.csv\",index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>[0.51597196 0.7554017  0.5300176  0.517211   0...</td>\n",
       "      <td>situp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>[0.23359461 0.16454183 0.7902765  0.18385786 0...</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>[0.24369298 0.4916674  0.71635526 0.2371287  0...</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>[0.32907322 0.4519693  0.5307704  0.31067795 0...</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>[0.370668   0.4771567  0.70738584 0.35307693 0...</td>\n",
       "      <td>situp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>[0.7021378  0.81637746 0.6464952  0.6785443  0...</td>\n",
       "      <td>pushup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[0.3311606  0.4952139  0.5822029  0.31286493 0...</td>\n",
       "      <td>hammer curl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>[0.7345542  0.10084037 0.5766364  0.6912343  0...</td>\n",
       "      <td>pushup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>[0.31775635 0.35093245 0.67397606 0.29555026 0...</td>\n",
       "      <td>tricep dips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>[0.30463085 0.5750473  0.69174707 0.28399628 0...</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   data        label\n",
       "1760  [0.51597196 0.7554017  0.5300176  0.517211   0...        situp\n",
       "749   [0.23359461 0.16454183 0.7902765  0.18385786 0...        squat\n",
       "503   [0.24369298 0.4916674  0.71635526 0.2371287  0...        squat\n",
       "481   [0.32907322 0.4519693  0.5307704  0.31067795 0...        squat\n",
       "2372  [0.370668   0.4771567  0.70738584 0.35307693 0...        situp\n",
       "...                                                 ...          ...\n",
       "1423  [0.7021378  0.81637746 0.6464952  0.6785443  0...       pushup\n",
       "167   [0.3311606  0.4952139  0.5822029  0.31286493 0...  hammer curl\n",
       "1533  [0.7345542  0.10084037 0.5766364  0.6912343  0...       pushup\n",
       "648   [0.31775635 0.35093245 0.67397606 0.29555026 0...  tricep dips\n",
       "579   [0.30463085 0.5750473  0.69174707 0.28399628 0...        squat\n",
       "\n",
       "[1270 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hammer curl' 'pushup' 'hip thrust' 'squat' 'situp' 'tricep pushdown'\n",
      " 'pull up' 'leg raises' 'barbell biceps curl' 'tricep dips'\n",
      " 'russian twist' 'standingFront' 'lateral raises' 'standingSide']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pose_landmarks(train_path,val_path,test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    val_df = pd.read_csv(val_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    \n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    X_test = []\n",
    "    temp_x_train = train_df.pop(\"data\")\n",
    "    temp_x_val = val_df.pop(\"data\")\n",
    "    temp_x_test = test_df.pop(\"data\")\n",
    "    \n",
    "    for data in temp_x_train:\n",
    "        spliited = data.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\n\",\"\").replace(\"  \",\" \").split(\" \")\n",
    "        data = np.array([float(i) for i in spliited if i != \"\"])\n",
    "        data = data.astype(np.float64)\n",
    "        X_train.append(data)\n",
    "        \n",
    "    for data in temp_x_val:\n",
    "        spliited = data.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\n\",\"\").replace(\"  \",\" \").split(\" \")\n",
    "        data = np.array([float(i) for i in spliited if i != \"\"])\n",
    "        data = data.astype(np.float64)\n",
    "        X_val.append(data)\n",
    "    \n",
    "    for data in temp_x_test:\n",
    "        spliited = data.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\n\",\"\").replace(\"  \",\" \").split(\" \")\n",
    "        data = np.array([float(i) for i in spliited if i != \"\"])\n",
    "        data = data.astype(np.float64)\n",
    "        X_test.append(data)\n",
    "    \n",
    "   \n",
    "    \n",
    "    classes = train_df[\"label\"].unique()\n",
    "    train_df[\"label_no\"] = train_df[\"label\"].apply(lambda x: np.where(classes == x)[0][0])\n",
    "    val_df[\"label_no\"] = val_df[\"label\"].apply(lambda x: np.where(classes == x)[0][0])\n",
    "    test_df[\"label_no\"] = test_df[\"label\"].apply(lambda x: np.where(classes == x)[0][0])\n",
    "    \n",
    "    \n",
    "\n",
    "    y_train = tf.keras.utils.to_categorical(train_df.pop(\"label_no\"))\n",
    "    y_val = tf.keras.utils.to_categorical(val_df.pop(\"label_no\"))\n",
    "    y_test = tf.keras.utils.to_categorical(test_df.pop(\"label_no\"))\n",
    "    \n",
    "    \n",
    "    X_train = tf.stack(X_train)\n",
    "    X_val = tf.stack(X_val)\n",
    "    X_test = tf.stack(X_test)\n",
    "    y_train = tf.stack(y_train)\n",
    "    y_val = tf.stack(y_val)\n",
    "    y_test = tf.stack(y_test)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test,classes\n",
    "\n",
    "X_train,X_val,X_test,y_train,y_val,y_test,classes = pose_landmarks(\"../../Datasets/Trainer/csv_processed/train.csv\",\"../../Datasets/Trainer/csv_processed/val.csv\",\"../../Datasets/Trainer/csv_processed/test.csv\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " data_input (InputLayer)     [(None, 51)]              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               13312     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " pose (Dense)                (None, 14)                3598      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 247182 (965.55 KB)\n",
      "Trainable params: 247182 (965.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def landmark_to_embedding(landmark):\n",
    "    \n",
    "    embedding = tf.keras.layers.Reshape((17, 3))(landmark)\n",
    "    return embedding\n",
    "\n",
    "inputs = tf.keras.Input(shape=(51),name=\"data_input\")\n",
    "layer = tf.keras.layers.Dense(256, activation=tf.nn.relu6)(inputs)\n",
    "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
    "layer = tf.keras.layers.Dense(512, activation=tf.nn.relu6)(layer)\n",
    "layer = tf.keras.layers.Dropout(0.5)(layer)\n",
    "layer = tf.keras.layers.Dense(128, activation=tf.nn.relu6)(layer)\n",
    "layer = tf.keras.layers.Dropout(0.2)(layer)\n",
    "layer = tf.keras.layers.Dense(256, activation=tf.nn.relu6)(layer)\n",
    "# layer2 = tf.keras.layers.Dense(256, activation=tf.nn.relu6)(layer)\n",
    "outputs_1 = tf.keras.layers.Dense(len(classes), activation=\"softmax\",name=\"pose\")(layer)\n",
    "#\n",
    "# outputs_3 = tf.keras.layers.Dense(6,name=\"angle\")(layer2)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs_1)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 9ms/step - loss: 1.6691 - accuracy: 0.4679 - val_loss: 1.1540 - val_accuracy: 0.6054\n",
      "Epoch 2/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 1.1699 - accuracy: 0.6124 - val_loss: 0.9636 - val_accuracy: 0.6833\n",
      "Epoch 3/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.9927 - accuracy: 0.6659 - val_loss: 0.7857 - val_accuracy: 0.7279\n",
      "Epoch 4/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.9126 - accuracy: 0.6884 - val_loss: 0.7046 - val_accuracy: 0.7612\n",
      "Epoch 5/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.8507 - accuracy: 0.7074 - val_loss: 0.6366 - val_accuracy: 0.7787\n",
      "Epoch 6/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.7983 - accuracy: 0.7277 - val_loss: 0.6136 - val_accuracy: 0.7944\n",
      "Epoch 7/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.7534 - accuracy: 0.7405 - val_loss: 0.5564 - val_accuracy: 0.8110\n",
      "Epoch 8/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.7512 - accuracy: 0.7439 - val_loss: 0.5485 - val_accuracy: 0.8128\n",
      "Epoch 9/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.7085 - accuracy: 0.7579 - val_loss: 0.5261 - val_accuracy: 0.8241\n",
      "Epoch 10/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.6884 - accuracy: 0.7633 - val_loss: 0.5451 - val_accuracy: 0.8093\n",
      "Epoch 11/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.6618 - accuracy: 0.7712 - val_loss: 0.4840 - val_accuracy: 0.8320\n",
      "Epoch 12/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.6433 - accuracy: 0.7785 - val_loss: 0.4442 - val_accuracy: 0.8486\n",
      "Epoch 13/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.6227 - accuracy: 0.7824 - val_loss: 0.4385 - val_accuracy: 0.8548\n",
      "Epoch 14/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.6075 - accuracy: 0.7895 - val_loss: 0.4537 - val_accuracy: 0.8469\n",
      "Epoch 15/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.5927 - accuracy: 0.7935 - val_loss: 0.4045 - val_accuracy: 0.8670\n",
      "Epoch 16/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.5624 - accuracy: 0.8049 - val_loss: 0.4016 - val_accuracy: 0.8801\n",
      "Epoch 17/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.5587 - accuracy: 0.8050 - val_loss: 0.3917 - val_accuracy: 0.8784\n",
      "Epoch 18/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.8107 - val_loss: 0.3695 - val_accuracy: 0.8696\n",
      "Epoch 19/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.5251 - accuracy: 0.8170 - val_loss: 0.3587 - val_accuracy: 0.8766\n",
      "Epoch 20/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.5096 - accuracy: 0.8264 - val_loss: 0.3359 - val_accuracy: 0.8924\n",
      "Epoch 21/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.8181 - val_loss: 0.3487 - val_accuracy: 0.8898\n",
      "Epoch 22/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.8206 - val_loss: 0.3098 - val_accuracy: 0.8941\n",
      "Epoch 23/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.8325 - val_loss: 0.3378 - val_accuracy: 0.8976\n",
      "Epoch 24/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.8348 - val_loss: 0.2991 - val_accuracy: 0.9003\n",
      "Epoch 25/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.4746 - accuracy: 0.8361 - val_loss: 0.2992 - val_accuracy: 0.9020\n",
      "Epoch 26/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.4654 - accuracy: 0.8370 - val_loss: 0.2778 - val_accuracy: 0.9116\n",
      "Epoch 27/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.8412 - val_loss: 0.2664 - val_accuracy: 0.9160\n",
      "Epoch 28/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4378 - accuracy: 0.8475 - val_loss: 0.2744 - val_accuracy: 0.9125\n",
      "Epoch 29/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4424 - accuracy: 0.8439 - val_loss: 0.2570 - val_accuracy: 0.9186\n",
      "Epoch 30/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.4336 - accuracy: 0.8519 - val_loss: 0.2774 - val_accuracy: 0.9081\n",
      "Epoch 31/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.4293 - accuracy: 0.8545 - val_loss: 0.2779 - val_accuracy: 0.9169\n",
      "Epoch 32/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4373 - accuracy: 0.8466 - val_loss: 0.2613 - val_accuracy: 0.9099\n",
      "Epoch 33/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4206 - accuracy: 0.8519 - val_loss: 0.2768 - val_accuracy: 0.9099\n",
      "Epoch 34/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8594 - val_loss: 0.2485 - val_accuracy: 0.9265\n",
      "Epoch 35/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4222 - accuracy: 0.8551 - val_loss: 0.2457 - val_accuracy: 0.9230\n",
      "Epoch 36/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8604 - val_loss: 0.2420 - val_accuracy: 0.9248\n",
      "Epoch 37/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3903 - accuracy: 0.8671 - val_loss: 0.2319 - val_accuracy: 0.9291\n",
      "Epoch 38/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.4034 - accuracy: 0.8606 - val_loss: 0.2399 - val_accuracy: 0.9274\n",
      "Epoch 39/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3789 - accuracy: 0.8674 - val_loss: 0.2217 - val_accuracy: 0.9283\n",
      "Epoch 40/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3953 - accuracy: 0.8605 - val_loss: 0.2125 - val_accuracy: 0.9335\n",
      "Epoch 41/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3948 - accuracy: 0.8627 - val_loss: 0.2157 - val_accuracy: 0.9344\n",
      "Epoch 42/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3930 - accuracy: 0.8652 - val_loss: 0.2267 - val_accuracy: 0.9230\n",
      "Epoch 43/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3761 - accuracy: 0.8699 - val_loss: 0.2090 - val_accuracy: 0.9265\n",
      "Epoch 44/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3808 - accuracy: 0.8691 - val_loss: 0.2257 - val_accuracy: 0.9361\n",
      "Epoch 45/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3700 - accuracy: 0.8732 - val_loss: 0.2086 - val_accuracy: 0.9256\n",
      "Epoch 46/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3856 - accuracy: 0.8681 - val_loss: 0.2286 - val_accuracy: 0.9178\n",
      "Epoch 47/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3540 - accuracy: 0.8792 - val_loss: 0.2038 - val_accuracy: 0.9283\n",
      "Epoch 48/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.3681 - accuracy: 0.8731 - val_loss: 0.2202 - val_accuracy: 0.9318\n",
      "Epoch 49/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3474 - accuracy: 0.8805 - val_loss: 0.2028 - val_accuracy: 0.9379\n",
      "Epoch 50/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3401 - accuracy: 0.8830 - val_loss: 0.1998 - val_accuracy: 0.9353\n",
      "Epoch 51/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3452 - accuracy: 0.8852 - val_loss: 0.2028 - val_accuracy: 0.9370\n",
      "Epoch 52/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3420 - accuracy: 0.8816 - val_loss: 0.1884 - val_accuracy: 0.9414\n",
      "Epoch 53/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3416 - accuracy: 0.8823 - val_loss: 0.1756 - val_accuracy: 0.9440\n",
      "Epoch 54/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8832 - val_loss: 0.2076 - val_accuracy: 0.9353\n",
      "Epoch 55/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3411 - accuracy: 0.8838 - val_loss: 0.1847 - val_accuracy: 0.9449\n",
      "Epoch 56/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8839 - val_loss: 0.1857 - val_accuracy: 0.9440\n",
      "Epoch 57/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8853 - val_loss: 0.2084 - val_accuracy: 0.9265\n",
      "Epoch 58/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3300 - accuracy: 0.8862 - val_loss: 0.1846 - val_accuracy: 0.9449\n",
      "Epoch 59/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8908 - val_loss: 0.1635 - val_accuracy: 0.9536\n",
      "Epoch 60/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3220 - accuracy: 0.8877 - val_loss: 0.1750 - val_accuracy: 0.9431\n",
      "Epoch 61/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3262 - accuracy: 0.8847 - val_loss: 0.1648 - val_accuracy: 0.9466\n",
      "Epoch 62/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3161 - accuracy: 0.8939 - val_loss: 0.1874 - val_accuracy: 0.9388\n",
      "Epoch 63/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3157 - accuracy: 0.8919 - val_loss: 0.1733 - val_accuracy: 0.9396\n",
      "Epoch 64/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2983 - accuracy: 0.8960 - val_loss: 0.1520 - val_accuracy: 0.9528\n",
      "Epoch 65/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3110 - accuracy: 0.8934 - val_loss: 0.1781 - val_accuracy: 0.9440\n",
      "Epoch 66/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3001 - accuracy: 0.8969 - val_loss: 0.1758 - val_accuracy: 0.9440\n",
      "Epoch 67/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3113 - accuracy: 0.8897 - val_loss: 0.1585 - val_accuracy: 0.9458\n",
      "Epoch 68/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3064 - accuracy: 0.8924 - val_loss: 0.1693 - val_accuracy: 0.9405\n",
      "Epoch 69/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3217 - accuracy: 0.8930 - val_loss: 0.1741 - val_accuracy: 0.9458\n",
      "Epoch 70/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3015 - accuracy: 0.8966 - val_loss: 0.1830 - val_accuracy: 0.9396\n",
      "Epoch 71/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3130 - accuracy: 0.8929 - val_loss: 0.1674 - val_accuracy: 0.9501\n",
      "Epoch 72/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.3074 - accuracy: 0.8955 - val_loss: 0.1644 - val_accuracy: 0.9484\n",
      "Epoch 73/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2990 - accuracy: 0.8979 - val_loss: 0.1740 - val_accuracy: 0.9510\n",
      "Epoch 74/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3040 - accuracy: 0.8940 - val_loss: 0.1621 - val_accuracy: 0.9536\n",
      "Epoch 75/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2995 - accuracy: 0.9003 - val_loss: 0.1635 - val_accuracy: 0.9440\n",
      "Epoch 76/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2972 - accuracy: 0.8955 - val_loss: 0.1545 - val_accuracy: 0.9501\n",
      "Epoch 77/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2966 - accuracy: 0.8979 - val_loss: 0.1637 - val_accuracy: 0.9510\n",
      "Epoch 78/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2960 - accuracy: 0.8963 - val_loss: 0.1494 - val_accuracy: 0.9536\n",
      "Epoch 79/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2924 - accuracy: 0.9020 - val_loss: 0.1722 - val_accuracy: 0.9458\n",
      "Epoch 80/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2811 - accuracy: 0.9016 - val_loss: 0.1575 - val_accuracy: 0.9475\n",
      "Epoch 81/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3025 - accuracy: 0.8959 - val_loss: 0.1758 - val_accuracy: 0.9458\n",
      "Epoch 82/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2992 - accuracy: 0.8987 - val_loss: 0.1407 - val_accuracy: 0.9519\n",
      "Epoch 83/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2911 - accuracy: 0.9006 - val_loss: 0.1499 - val_accuracy: 0.9536\n",
      "Epoch 84/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2840 - accuracy: 0.9051 - val_loss: 0.1421 - val_accuracy: 0.9563\n",
      "Epoch 85/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2685 - accuracy: 0.9072 - val_loss: 0.1444 - val_accuracy: 0.9571\n",
      "Epoch 86/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2734 - accuracy: 0.9067 - val_loss: 0.1520 - val_accuracy: 0.9528\n",
      "Epoch 87/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2854 - accuracy: 0.9069 - val_loss: 0.1528 - val_accuracy: 0.9466\n",
      "Epoch 88/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2714 - accuracy: 0.9041 - val_loss: 0.1543 - val_accuracy: 0.9501\n",
      "Epoch 89/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.2868 - accuracy: 0.9021 - val_loss: 0.1504 - val_accuracy: 0.9554\n",
      "Epoch 90/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2689 - accuracy: 0.9080 - val_loss: 0.1393 - val_accuracy: 0.9554\n",
      "Epoch 91/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2686 - accuracy: 0.9078 - val_loss: 0.1508 - val_accuracy: 0.9536\n",
      "Epoch 92/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2647 - accuracy: 0.9092 - val_loss: 0.1435 - val_accuracy: 0.9475\n",
      "Epoch 93/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2688 - accuracy: 0.9084 - val_loss: 0.1562 - val_accuracy: 0.9580\n",
      "Epoch 94/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2654 - accuracy: 0.9077 - val_loss: 0.1491 - val_accuracy: 0.9493\n",
      "Epoch 95/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2674 - accuracy: 0.9101 - val_loss: 0.1455 - val_accuracy: 0.9536\n",
      "Epoch 96/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2752 - accuracy: 0.9049 - val_loss: 0.1389 - val_accuracy: 0.9563\n",
      "Epoch 97/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2714 - accuracy: 0.9067 - val_loss: 0.1440 - val_accuracy: 0.9563\n",
      "Epoch 98/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2832 - accuracy: 0.9021 - val_loss: 0.1416 - val_accuracy: 0.9536\n",
      "Epoch 99/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2608 - accuracy: 0.9089 - val_loss: 0.1316 - val_accuracy: 0.9563\n",
      "Epoch 100/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2785 - accuracy: 0.9072 - val_loss: 0.1325 - val_accuracy: 0.9633\n",
      "Epoch 101/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2625 - accuracy: 0.9078 - val_loss: 0.1380 - val_accuracy: 0.9545\n",
      "Epoch 102/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2624 - accuracy: 0.9099 - val_loss: 0.1363 - val_accuracy: 0.9624\n",
      "Epoch 103/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2422 - accuracy: 0.9138 - val_loss: 0.1496 - val_accuracy: 0.9484\n",
      "Epoch 104/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2583 - accuracy: 0.9109 - val_loss: 0.1304 - val_accuracy: 0.9606\n",
      "Epoch 105/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2544 - accuracy: 0.9136 - val_loss: 0.1489 - val_accuracy: 0.9519\n",
      "Epoch 106/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2592 - accuracy: 0.9120 - val_loss: 0.1608 - val_accuracy: 0.9458\n",
      "Epoch 107/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2473 - accuracy: 0.9137 - val_loss: 0.1454 - val_accuracy: 0.9528\n",
      "Epoch 108/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2587 - accuracy: 0.9087 - val_loss: 0.1373 - val_accuracy: 0.9598\n",
      "Epoch 109/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2593 - accuracy: 0.9101 - val_loss: 0.1577 - val_accuracy: 0.9571\n",
      "Epoch 110/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2691 - accuracy: 0.9115 - val_loss: 0.1426 - val_accuracy: 0.9563\n",
      "Epoch 111/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2484 - accuracy: 0.9127 - val_loss: 0.1547 - val_accuracy: 0.9571\n",
      "Epoch 112/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2551 - accuracy: 0.9094 - val_loss: 0.1305 - val_accuracy: 0.9598\n",
      "Epoch 113/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2628 - accuracy: 0.9073 - val_loss: 0.1234 - val_accuracy: 0.9571\n",
      "Epoch 114/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2449 - accuracy: 0.9170 - val_loss: 0.1415 - val_accuracy: 0.9510\n",
      "Epoch 115/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2416 - accuracy: 0.9172 - val_loss: 0.1434 - val_accuracy: 0.9493\n",
      "Epoch 116/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2623 - accuracy: 0.9102 - val_loss: 0.1445 - val_accuracy: 0.9519\n",
      "Epoch 117/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2516 - accuracy: 0.9132 - val_loss: 0.1329 - val_accuracy: 0.9571\n",
      "Epoch 118/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2451 - accuracy: 0.9165 - val_loss: 0.1489 - val_accuracy: 0.9501\n",
      "Epoch 119/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2399 - accuracy: 0.9181 - val_loss: 0.1418 - val_accuracy: 0.9563\n",
      "Epoch 120/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2530 - accuracy: 0.9136 - val_loss: 0.1338 - val_accuracy: 0.9589\n",
      "Epoch 121/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2428 - accuracy: 0.9166 - val_loss: 0.1325 - val_accuracy: 0.9545\n",
      "Epoch 122/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2382 - accuracy: 0.9209 - val_loss: 0.1346 - val_accuracy: 0.9563\n",
      "Epoch 123/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2410 - accuracy: 0.9176 - val_loss: 0.1315 - val_accuracy: 0.9606\n",
      "Epoch 124/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2297 - accuracy: 0.9208 - val_loss: 0.1536 - val_accuracy: 0.9501\n",
      "Epoch 125/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2430 - accuracy: 0.9147 - val_loss: 0.1311 - val_accuracy: 0.9589\n",
      "Epoch 126/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2429 - accuracy: 0.9182 - val_loss: 0.1292 - val_accuracy: 0.9606\n",
      "Epoch 127/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2415 - accuracy: 0.9148 - val_loss: 0.1421 - val_accuracy: 0.9580\n",
      "Epoch 128/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2447 - accuracy: 0.9176 - val_loss: 0.1219 - val_accuracy: 0.9606\n",
      "Epoch 129/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2375 - accuracy: 0.9174 - val_loss: 0.1371 - val_accuracy: 0.9545\n",
      "Epoch 130/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2320 - accuracy: 0.9212 - val_loss: 0.1456 - val_accuracy: 0.9536\n",
      "Epoch 131/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2287 - accuracy: 0.9224 - val_loss: 0.1212 - val_accuracy: 0.9580\n",
      "Epoch 132/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2184 - accuracy: 0.9237 - val_loss: 0.1203 - val_accuracy: 0.9615\n",
      "Epoch 133/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.9196 - val_loss: 0.1213 - val_accuracy: 0.9624\n",
      "Epoch 134/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2274 - accuracy: 0.9245 - val_loss: 0.1204 - val_accuracy: 0.9615\n",
      "Epoch 135/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2386 - accuracy: 0.9187 - val_loss: 0.1408 - val_accuracy: 0.9536\n",
      "Epoch 136/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2386 - accuracy: 0.9198 - val_loss: 0.1330 - val_accuracy: 0.9571\n",
      "Epoch 137/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2307 - accuracy: 0.9199 - val_loss: 0.1286 - val_accuracy: 0.9624\n",
      "Epoch 138/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2290 - accuracy: 0.9225 - val_loss: 0.1156 - val_accuracy: 0.9633\n",
      "Epoch 139/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2281 - accuracy: 0.9223 - val_loss: 0.1332 - val_accuracy: 0.9571\n",
      "Epoch 140/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2253 - accuracy: 0.9235 - val_loss: 0.1189 - val_accuracy: 0.9624\n",
      "Epoch 141/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2453 - accuracy: 0.9171 - val_loss: 0.1164 - val_accuracy: 0.9659\n",
      "Epoch 142/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2302 - accuracy: 0.9238 - val_loss: 0.1233 - val_accuracy: 0.9615\n",
      "Epoch 143/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2353 - accuracy: 0.9193 - val_loss: 0.1339 - val_accuracy: 0.9606\n",
      "Epoch 144/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9242 - val_loss: 0.1165 - val_accuracy: 0.9668\n",
      "Epoch 145/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2266 - accuracy: 0.9226 - val_loss: 0.1193 - val_accuracy: 0.9633\n",
      "Epoch 146/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2402 - accuracy: 0.9192 - val_loss: 0.1261 - val_accuracy: 0.9598\n",
      "Epoch 147/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2318 - accuracy: 0.9211 - val_loss: 0.1170 - val_accuracy: 0.9615\n",
      "Epoch 148/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2287 - accuracy: 0.9229 - val_loss: 0.1229 - val_accuracy: 0.9598\n",
      "Epoch 149/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2232 - accuracy: 0.9212 - val_loss: 0.1121 - val_accuracy: 0.9650\n",
      "Epoch 150/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.9218 - val_loss: 0.1082 - val_accuracy: 0.9676\n",
      "Epoch 151/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9264 - val_loss: 0.1178 - val_accuracy: 0.9633\n",
      "Epoch 152/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2240 - accuracy: 0.9245 - val_loss: 0.1228 - val_accuracy: 0.9650\n",
      "Epoch 153/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2247 - accuracy: 0.9228 - val_loss: 0.1113 - val_accuracy: 0.9598\n",
      "Epoch 154/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2221 - accuracy: 0.9237 - val_loss: 0.1307 - val_accuracy: 0.9554\n",
      "Epoch 155/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2329 - accuracy: 0.9214 - val_loss: 0.1218 - val_accuracy: 0.9659\n",
      "Epoch 156/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2366 - accuracy: 0.9192 - val_loss: 0.1259 - val_accuracy: 0.9589\n",
      "Epoch 157/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2186 - accuracy: 0.9249 - val_loss: 0.1075 - val_accuracy: 0.9685\n",
      "Epoch 158/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9256 - val_loss: 0.1096 - val_accuracy: 0.9694\n",
      "Epoch 159/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2146 - accuracy: 0.9238 - val_loss: 0.1099 - val_accuracy: 0.9685\n",
      "Epoch 160/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2235 - accuracy: 0.9222 - val_loss: 0.1181 - val_accuracy: 0.9633\n",
      "Epoch 161/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2150 - accuracy: 0.9298 - val_loss: 0.1274 - val_accuracy: 0.9633\n",
      "Epoch 162/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2207 - accuracy: 0.9248 - val_loss: 0.1084 - val_accuracy: 0.9624\n",
      "Epoch 163/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9237 - val_loss: 0.1018 - val_accuracy: 0.9694\n",
      "Epoch 164/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2117 - accuracy: 0.9244 - val_loss: 0.1152 - val_accuracy: 0.9633\n",
      "Epoch 165/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2255 - accuracy: 0.9251 - val_loss: 0.1129 - val_accuracy: 0.9641\n",
      "Epoch 166/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2168 - accuracy: 0.9225 - val_loss: 0.1258 - val_accuracy: 0.9606\n",
      "Epoch 167/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2197 - accuracy: 0.9223 - val_loss: 0.1113 - val_accuracy: 0.9633\n",
      "Epoch 168/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2245 - accuracy: 0.9231 - val_loss: 0.1166 - val_accuracy: 0.9668\n",
      "Epoch 169/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2163 - accuracy: 0.9262 - val_loss: 0.1233 - val_accuracy: 0.9624\n",
      "Epoch 170/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2196 - accuracy: 0.9235 - val_loss: 0.1122 - val_accuracy: 0.9668\n",
      "Epoch 171/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2201 - accuracy: 0.9225 - val_loss: 0.1258 - val_accuracy: 0.9563\n",
      "Epoch 172/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9267 - val_loss: 0.1200 - val_accuracy: 0.9589\n",
      "Epoch 173/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2012 - accuracy: 0.9331 - val_loss: 0.1065 - val_accuracy: 0.9668\n",
      "Epoch 174/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2085 - accuracy: 0.9300 - val_loss: 0.1186 - val_accuracy: 0.9615\n",
      "Epoch 175/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2106 - accuracy: 0.9291 - val_loss: 0.1173 - val_accuracy: 0.9659\n",
      "Epoch 176/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2078 - accuracy: 0.9295 - val_loss: 0.1128 - val_accuracy: 0.9650\n",
      "Epoch 177/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2185 - accuracy: 0.9244 - val_loss: 0.1225 - val_accuracy: 0.9615\n",
      "Epoch 178/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2073 - accuracy: 0.9294 - val_loss: 0.1191 - val_accuracy: 0.9633\n",
      "Epoch 179/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1977 - accuracy: 0.9332 - val_loss: 0.1122 - val_accuracy: 0.9633\n",
      "Epoch 180/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2244 - accuracy: 0.9233 - val_loss: 0.1202 - val_accuracy: 0.9606\n",
      "Epoch 181/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2078 - accuracy: 0.9289 - val_loss: 0.1068 - val_accuracy: 0.9650\n",
      "Epoch 182/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9294 - val_loss: 0.1058 - val_accuracy: 0.9729\n",
      "Epoch 183/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9271 - val_loss: 0.1242 - val_accuracy: 0.9589\n",
      "Epoch 184/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1969 - accuracy: 0.9328 - val_loss: 0.1155 - val_accuracy: 0.9624\n",
      "Epoch 185/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2029 - accuracy: 0.9296 - val_loss: 0.1014 - val_accuracy: 0.9729\n",
      "Epoch 186/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1969 - accuracy: 0.9306 - val_loss: 0.1217 - val_accuracy: 0.9624\n",
      "Epoch 187/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2085 - accuracy: 0.9280 - val_loss: 0.1125 - val_accuracy: 0.9641\n",
      "Epoch 188/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9285 - val_loss: 0.1192 - val_accuracy: 0.9685\n",
      "Epoch 189/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2172 - accuracy: 0.9285 - val_loss: 0.1030 - val_accuracy: 0.9676\n",
      "Epoch 190/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2040 - accuracy: 0.9314 - val_loss: 0.1151 - val_accuracy: 0.9633\n",
      "Epoch 191/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9293 - val_loss: 0.1152 - val_accuracy: 0.9633\n",
      "Epoch 192/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9267 - val_loss: 0.1347 - val_accuracy: 0.9563\n",
      "Epoch 193/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2014 - accuracy: 0.9307 - val_loss: 0.1057 - val_accuracy: 0.9676\n",
      "Epoch 194/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9298 - val_loss: 0.1213 - val_accuracy: 0.9545\n",
      "Epoch 195/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2185 - accuracy: 0.9274 - val_loss: 0.1156 - val_accuracy: 0.9571\n",
      "Epoch 196/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9303 - val_loss: 0.1145 - val_accuracy: 0.9650\n",
      "Epoch 197/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1938 - accuracy: 0.9357 - val_loss: 0.1086 - val_accuracy: 0.9694\n",
      "Epoch 198/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9308 - val_loss: 0.1106 - val_accuracy: 0.9606\n",
      "Epoch 199/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1994 - accuracy: 0.9325 - val_loss: 0.1041 - val_accuracy: 0.9703\n",
      "Epoch 200/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2026 - accuracy: 0.9337 - val_loss: 0.1108 - val_accuracy: 0.9685\n",
      "Epoch 201/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1983 - accuracy: 0.9331 - val_loss: 0.1209 - val_accuracy: 0.9571\n",
      "Epoch 202/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1923 - accuracy: 0.9324 - val_loss: 0.1182 - val_accuracy: 0.9598\n",
      "Epoch 203/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2072 - accuracy: 0.9286 - val_loss: 0.1009 - val_accuracy: 0.9711\n",
      "Epoch 204/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2112 - accuracy: 0.9267 - val_loss: 0.1049 - val_accuracy: 0.9685\n",
      "Epoch 205/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1888 - accuracy: 0.9347 - val_loss: 0.1078 - val_accuracy: 0.9685\n",
      "Epoch 206/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1870 - accuracy: 0.9356 - val_loss: 0.1110 - val_accuracy: 0.9624\n",
      "Epoch 207/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2105 - accuracy: 0.9253 - val_loss: 0.1214 - val_accuracy: 0.9554\n",
      "Epoch 208/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2014 - accuracy: 0.9310 - val_loss: 0.1115 - val_accuracy: 0.9606\n",
      "Epoch 209/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9291 - val_loss: 0.1126 - val_accuracy: 0.9641\n",
      "Epoch 210/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1853 - accuracy: 0.9361 - val_loss: 0.1070 - val_accuracy: 0.9641\n",
      "Epoch 211/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2033 - accuracy: 0.9331 - val_loss: 0.1135 - val_accuracy: 0.9650\n",
      "Epoch 212/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1899 - accuracy: 0.9345 - val_loss: 0.1053 - val_accuracy: 0.9668\n",
      "Epoch 213/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1919 - accuracy: 0.9343 - val_loss: 0.1102 - val_accuracy: 0.9624\n",
      "Epoch 214/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1954 - accuracy: 0.9315 - val_loss: 0.1181 - val_accuracy: 0.9624\n",
      "Epoch 215/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1936 - accuracy: 0.9364 - val_loss: 0.1243 - val_accuracy: 0.9554\n",
      "Epoch 216/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9304 - val_loss: 0.0982 - val_accuracy: 0.9703\n",
      "Epoch 217/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1883 - accuracy: 0.9348 - val_loss: 0.1072 - val_accuracy: 0.9641\n",
      "Epoch 218/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2022 - accuracy: 0.9335 - val_loss: 0.0950 - val_accuracy: 0.9720\n",
      "Epoch 219/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1859 - accuracy: 0.9371 - val_loss: 0.1012 - val_accuracy: 0.9685\n",
      "Epoch 220/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1887 - accuracy: 0.9355 - val_loss: 0.1170 - val_accuracy: 0.9624\n",
      "Epoch 221/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1883 - accuracy: 0.9335 - val_loss: 0.1044 - val_accuracy: 0.9711\n",
      "Epoch 222/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1968 - accuracy: 0.9305 - val_loss: 0.1092 - val_accuracy: 0.9641\n",
      "Epoch 223/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1989 - accuracy: 0.9322 - val_loss: 0.1219 - val_accuracy: 0.9650\n",
      "Epoch 224/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1913 - accuracy: 0.9384 - val_loss: 0.1052 - val_accuracy: 0.9685\n",
      "Epoch 225/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2020 - accuracy: 0.9367 - val_loss: 0.1143 - val_accuracy: 0.9668\n",
      "Epoch 226/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1921 - accuracy: 0.9351 - val_loss: 0.1122 - val_accuracy: 0.9659\n",
      "Epoch 227/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1905 - accuracy: 0.9342 - val_loss: 0.1029 - val_accuracy: 0.9641\n",
      "Epoch 228/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2012 - accuracy: 0.9329 - val_loss: 0.1049 - val_accuracy: 0.9641\n",
      "Epoch 229/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1710 - accuracy: 0.9419 - val_loss: 0.1025 - val_accuracy: 0.9676\n",
      "Epoch 230/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1945 - accuracy: 0.9352 - val_loss: 0.1060 - val_accuracy: 0.9685\n",
      "Epoch 231/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1853 - accuracy: 0.9351 - val_loss: 0.1049 - val_accuracy: 0.9659\n",
      "Epoch 232/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9347 - val_loss: 0.1053 - val_accuracy: 0.9703\n",
      "Epoch 233/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1876 - accuracy: 0.9360 - val_loss: 0.1002 - val_accuracy: 0.9676\n",
      "Epoch 234/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1827 - accuracy: 0.9412 - val_loss: 0.0953 - val_accuracy: 0.9738\n",
      "Epoch 235/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1908 - accuracy: 0.9368 - val_loss: 0.1122 - val_accuracy: 0.9668\n",
      "Epoch 236/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1945 - accuracy: 0.9351 - val_loss: 0.1021 - val_accuracy: 0.9676\n",
      "Epoch 237/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9365 - val_loss: 0.1071 - val_accuracy: 0.9685\n",
      "Epoch 238/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1803 - accuracy: 0.9374 - val_loss: 0.1030 - val_accuracy: 0.9668\n",
      "Epoch 239/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.2061 - accuracy: 0.9312 - val_loss: 0.1032 - val_accuracy: 0.9676\n",
      "Epoch 240/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1760 - accuracy: 0.9405 - val_loss: 0.1024 - val_accuracy: 0.9729\n",
      "Epoch 241/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1739 - accuracy: 0.9415 - val_loss: 0.1093 - val_accuracy: 0.9659\n",
      "Epoch 242/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1775 - accuracy: 0.9375 - val_loss: 0.1113 - val_accuracy: 0.9624\n",
      "Epoch 243/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1870 - accuracy: 0.9375 - val_loss: 0.1070 - val_accuracy: 0.9633\n",
      "Epoch 244/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1946 - accuracy: 0.9351 - val_loss: 0.1097 - val_accuracy: 0.9641\n",
      "Epoch 245/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1730 - accuracy: 0.9401 - val_loss: 0.1016 - val_accuracy: 0.9676\n",
      "Epoch 246/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1868 - accuracy: 0.9356 - val_loss: 0.1007 - val_accuracy: 0.9668\n",
      "Epoch 247/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1914 - accuracy: 0.9352 - val_loss: 0.1001 - val_accuracy: 0.9703\n",
      "Epoch 248/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.9371 - val_loss: 0.1124 - val_accuracy: 0.9676\n",
      "Epoch 249/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1840 - accuracy: 0.9381 - val_loss: 0.1137 - val_accuracy: 0.9641\n",
      "Epoch 250/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.9378 - val_loss: 0.0968 - val_accuracy: 0.9711\n",
      "Epoch 251/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1609 - accuracy: 0.9457 - val_loss: 0.1006 - val_accuracy: 0.9703\n",
      "Epoch 252/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1873 - accuracy: 0.9361 - val_loss: 0.1119 - val_accuracy: 0.9659\n",
      "Epoch 253/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1928 - accuracy: 0.9348 - val_loss: 0.1044 - val_accuracy: 0.9711\n",
      "Epoch 254/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1829 - accuracy: 0.9371 - val_loss: 0.1039 - val_accuracy: 0.9659\n",
      "Epoch 255/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1989 - accuracy: 0.9354 - val_loss: 0.0987 - val_accuracy: 0.9703\n",
      "Epoch 256/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1796 - accuracy: 0.9378 - val_loss: 0.0971 - val_accuracy: 0.9676\n",
      "Epoch 257/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1805 - accuracy: 0.9389 - val_loss: 0.0960 - val_accuracy: 0.9711\n",
      "Epoch 258/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9421 - val_loss: 0.0976 - val_accuracy: 0.9711\n",
      "Epoch 259/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9398 - val_loss: 0.1062 - val_accuracy: 0.9694\n",
      "Epoch 260/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9382 - val_loss: 0.1059 - val_accuracy: 0.9650\n",
      "Epoch 261/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1773 - accuracy: 0.9413 - val_loss: 0.0933 - val_accuracy: 0.9764\n",
      "Epoch 262/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1922 - accuracy: 0.9347 - val_loss: 0.1040 - val_accuracy: 0.9720\n",
      "Epoch 263/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1784 - accuracy: 0.9416 - val_loss: 0.0985 - val_accuracy: 0.9659\n",
      "Epoch 264/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1777 - accuracy: 0.9393 - val_loss: 0.0994 - val_accuracy: 0.9685\n",
      "Epoch 265/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1774 - accuracy: 0.9396 - val_loss: 0.1060 - val_accuracy: 0.9676\n",
      "Epoch 266/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1842 - accuracy: 0.9375 - val_loss: 0.1007 - val_accuracy: 0.9729\n",
      "Epoch 267/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1869 - accuracy: 0.9385 - val_loss: 0.1151 - val_accuracy: 0.9624\n",
      "Epoch 268/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1788 - accuracy: 0.9368 - val_loss: 0.1000 - val_accuracy: 0.9659\n",
      "Epoch 269/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1712 - accuracy: 0.9411 - val_loss: 0.0964 - val_accuracy: 0.9685\n",
      "Epoch 270/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1838 - accuracy: 0.9391 - val_loss: 0.1070 - val_accuracy: 0.9685\n",
      "Epoch 271/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1772 - accuracy: 0.9408 - val_loss: 0.0949 - val_accuracy: 0.9711\n",
      "Epoch 272/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1903 - accuracy: 0.9364 - val_loss: 0.1032 - val_accuracy: 0.9685\n",
      "Epoch 273/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1843 - accuracy: 0.9384 - val_loss: 0.1057 - val_accuracy: 0.9624\n",
      "Epoch 274/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1879 - accuracy: 0.9343 - val_loss: 0.0984 - val_accuracy: 0.9703\n",
      "Epoch 275/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1791 - accuracy: 0.9390 - val_loss: 0.0973 - val_accuracy: 0.9685\n",
      "Epoch 276/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1620 - accuracy: 0.9460 - val_loss: 0.1037 - val_accuracy: 0.9659\n",
      "Epoch 277/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.9399 - val_loss: 0.1022 - val_accuracy: 0.9668\n",
      "Epoch 278/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1819 - accuracy: 0.9388 - val_loss: 0.1081 - val_accuracy: 0.9659\n",
      "Epoch 279/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1702 - accuracy: 0.9414 - val_loss: 0.0997 - val_accuracy: 0.9755\n",
      "Epoch 280/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.9379 - val_loss: 0.0973 - val_accuracy: 0.9668\n",
      "Epoch 281/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1732 - accuracy: 0.9403 - val_loss: 0.0924 - val_accuracy: 0.9685\n",
      "Epoch 282/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1887 - accuracy: 0.9379 - val_loss: 0.1054 - val_accuracy: 0.9685\n",
      "Epoch 283/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1864 - accuracy: 0.9393 - val_loss: 0.0960 - val_accuracy: 0.9659\n",
      "Epoch 284/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1631 - accuracy: 0.9440 - val_loss: 0.1086 - val_accuracy: 0.9738\n",
      "Epoch 285/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1692 - accuracy: 0.9420 - val_loss: 0.1120 - val_accuracy: 0.9659\n",
      "Epoch 286/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1733 - accuracy: 0.9387 - val_loss: 0.1098 - val_accuracy: 0.9659\n",
      "Epoch 287/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1724 - accuracy: 0.9398 - val_loss: 0.0965 - val_accuracy: 0.9676\n",
      "Epoch 288/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1904 - accuracy: 0.9362 - val_loss: 0.0975 - val_accuracy: 0.9703\n",
      "Epoch 289/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1673 - accuracy: 0.9458 - val_loss: 0.1034 - val_accuracy: 0.9703\n",
      "Epoch 290/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1752 - accuracy: 0.9421 - val_loss: 0.1003 - val_accuracy: 0.9711\n",
      "Epoch 291/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1689 - accuracy: 0.9435 - val_loss: 0.0959 - val_accuracy: 0.9703\n",
      "Epoch 292/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1752 - accuracy: 0.9443 - val_loss: 0.1004 - val_accuracy: 0.9685\n",
      "Epoch 293/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1774 - accuracy: 0.9396 - val_loss: 0.0929 - val_accuracy: 0.9746\n",
      "Epoch 294/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1813 - accuracy: 0.9370 - val_loss: 0.0935 - val_accuracy: 0.9738\n",
      "Epoch 295/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.9467 - val_loss: 0.1001 - val_accuracy: 0.9685\n",
      "Epoch 296/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1700 - accuracy: 0.9408 - val_loss: 0.1032 - val_accuracy: 0.9676\n",
      "Epoch 297/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1703 - accuracy: 0.9419 - val_loss: 0.0968 - val_accuracy: 0.9729\n",
      "Epoch 298/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1695 - accuracy: 0.9426 - val_loss: 0.1112 - val_accuracy: 0.9668\n",
      "Epoch 299/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1822 - accuracy: 0.9389 - val_loss: 0.0947 - val_accuracy: 0.9729\n",
      "Epoch 300/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1644 - accuracy: 0.9444 - val_loss: 0.1016 - val_accuracy: 0.9685\n",
      "Epoch 301/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1698 - accuracy: 0.9423 - val_loss: 0.0926 - val_accuracy: 0.9729\n",
      "Epoch 302/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1634 - accuracy: 0.9446 - val_loss: 0.1060 - val_accuracy: 0.9633\n",
      "Epoch 303/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1938 - accuracy: 0.9357 - val_loss: 0.0921 - val_accuracy: 0.9711\n",
      "Epoch 304/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1608 - accuracy: 0.9447 - val_loss: 0.0988 - val_accuracy: 0.9685\n",
      "Epoch 305/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1675 - accuracy: 0.9451 - val_loss: 0.1025 - val_accuracy: 0.9685\n",
      "Epoch 306/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1720 - accuracy: 0.9437 - val_loss: 0.0922 - val_accuracy: 0.9711\n",
      "Epoch 307/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1791 - accuracy: 0.9402 - val_loss: 0.0999 - val_accuracy: 0.9668\n",
      "Epoch 308/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1628 - accuracy: 0.9443 - val_loss: 0.1072 - val_accuracy: 0.9694\n",
      "Epoch 309/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1827 - accuracy: 0.9374 - val_loss: 0.0991 - val_accuracy: 0.9711\n",
      "Epoch 310/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.9443 - val_loss: 0.0940 - val_accuracy: 0.9720\n",
      "Epoch 311/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1709 - accuracy: 0.9419 - val_loss: 0.1041 - val_accuracy: 0.9659\n",
      "Epoch 312/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1739 - accuracy: 0.9431 - val_loss: 0.1011 - val_accuracy: 0.9659\n",
      "Epoch 313/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1594 - accuracy: 0.9453 - val_loss: 0.0948 - val_accuracy: 0.9729\n",
      "Epoch 314/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1690 - accuracy: 0.9438 - val_loss: 0.0934 - val_accuracy: 0.9694\n",
      "Epoch 315/1000\n",
      "161/161 [==============================] - 2s 12ms/step - loss: 0.1726 - accuracy: 0.9422 - val_loss: 0.0929 - val_accuracy: 0.9755\n",
      "Epoch 316/1000\n",
      "161/161 [==============================] - 2s 9ms/step - loss: 0.1770 - accuracy: 0.9396 - val_loss: 0.1013 - val_accuracy: 0.9703\n",
      "Epoch 317/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1713 - accuracy: 0.9423 - val_loss: 0.0955 - val_accuracy: 0.9711\n",
      "Epoch 318/1000\n",
      "161/161 [==============================] - 2s 10ms/step - loss: 0.1672 - accuracy: 0.9426 - val_loss: 0.0956 - val_accuracy: 0.9711\n",
      "Epoch 319/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1759 - accuracy: 0.9390 - val_loss: 0.1014 - val_accuracy: 0.9711\n",
      "Epoch 320/1000\n",
      "161/161 [==============================] - 2s 12ms/step - loss: 0.1558 - accuracy: 0.9472 - val_loss: 0.0964 - val_accuracy: 0.9694\n",
      "Epoch 321/1000\n",
      "161/161 [==============================] - 2s 10ms/step - loss: 0.1653 - accuracy: 0.9426 - val_loss: 0.1122 - val_accuracy: 0.9668\n",
      "Epoch 322/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1767 - accuracy: 0.9412 - val_loss: 0.1025 - val_accuracy: 0.9685\n",
      "Epoch 323/1000\n",
      "161/161 [==============================] - 2s 10ms/step - loss: 0.1729 - accuracy: 0.9399 - val_loss: 0.0959 - val_accuracy: 0.9738\n",
      "Epoch 324/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1579 - accuracy: 0.9465 - val_loss: 0.0995 - val_accuracy: 0.9703\n",
      "Epoch 325/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1586 - accuracy: 0.9478 - val_loss: 0.1020 - val_accuracy: 0.9685\n",
      "Epoch 326/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9405 - val_loss: 0.1101 - val_accuracy: 0.9711\n",
      "Epoch 327/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1685 - accuracy: 0.9426 - val_loss: 0.0995 - val_accuracy: 0.9711\n",
      "Epoch 328/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1522 - accuracy: 0.9492 - val_loss: 0.0965 - val_accuracy: 0.9746\n",
      "Epoch 329/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1603 - accuracy: 0.9459 - val_loss: 0.0974 - val_accuracy: 0.9738\n",
      "Epoch 330/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1752 - accuracy: 0.9420 - val_loss: 0.1011 - val_accuracy: 0.9659\n",
      "Epoch 331/1000\n",
      "161/161 [==============================] - 2s 9ms/step - loss: 0.1652 - accuracy: 0.9420 - val_loss: 0.1036 - val_accuracy: 0.9685\n",
      "Epoch 332/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1636 - accuracy: 0.9450 - val_loss: 0.0958 - val_accuracy: 0.9729\n",
      "Epoch 333/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1531 - accuracy: 0.9478 - val_loss: 0.1015 - val_accuracy: 0.9729\n",
      "Epoch 334/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1602 - accuracy: 0.9464 - val_loss: 0.1035 - val_accuracy: 0.9711\n",
      "Epoch 335/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1680 - accuracy: 0.9431 - val_loss: 0.1030 - val_accuracy: 0.9694\n",
      "Epoch 336/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.9446 - val_loss: 0.1059 - val_accuracy: 0.9694\n",
      "Epoch 337/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1643 - accuracy: 0.9455 - val_loss: 0.1097 - val_accuracy: 0.9676\n",
      "Epoch 338/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1599 - accuracy: 0.9467 - val_loss: 0.0959 - val_accuracy: 0.9711\n",
      "Epoch 339/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1626 - accuracy: 0.9438 - val_loss: 0.1070 - val_accuracy: 0.9703\n",
      "Epoch 340/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1542 - accuracy: 0.9493 - val_loss: 0.0876 - val_accuracy: 0.9755\n",
      "Epoch 341/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1644 - accuracy: 0.9462 - val_loss: 0.0987 - val_accuracy: 0.9711\n",
      "Epoch 342/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1728 - accuracy: 0.9409 - val_loss: 0.1175 - val_accuracy: 0.9598\n",
      "Epoch 343/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1609 - accuracy: 0.9489 - val_loss: 0.0953 - val_accuracy: 0.9738\n",
      "Epoch 344/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1596 - accuracy: 0.9466 - val_loss: 0.0962 - val_accuracy: 0.9676\n",
      "Epoch 345/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1734 - accuracy: 0.9428 - val_loss: 0.0923 - val_accuracy: 0.9746\n",
      "Epoch 346/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1669 - accuracy: 0.9442 - val_loss: 0.1048 - val_accuracy: 0.9676\n",
      "Epoch 347/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1619 - accuracy: 0.9464 - val_loss: 0.1138 - val_accuracy: 0.9694\n",
      "Epoch 348/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1703 - accuracy: 0.9419 - val_loss: 0.0958 - val_accuracy: 0.9694\n",
      "Epoch 349/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1592 - accuracy: 0.9474 - val_loss: 0.1005 - val_accuracy: 0.9650\n",
      "Epoch 350/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1526 - accuracy: 0.9480 - val_loss: 0.0933 - val_accuracy: 0.9711\n",
      "Epoch 351/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1602 - accuracy: 0.9468 - val_loss: 0.1052 - val_accuracy: 0.9703\n",
      "Epoch 352/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1680 - accuracy: 0.9439 - val_loss: 0.0953 - val_accuracy: 0.9729\n",
      "Epoch 353/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1575 - accuracy: 0.9484 - val_loss: 0.0979 - val_accuracy: 0.9711\n",
      "Epoch 354/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1638 - accuracy: 0.9450 - val_loss: 0.0901 - val_accuracy: 0.9738\n",
      "Epoch 355/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1553 - accuracy: 0.9473 - val_loss: 0.0886 - val_accuracy: 0.9729\n",
      "Epoch 356/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1633 - accuracy: 0.9458 - val_loss: 0.1038 - val_accuracy: 0.9694\n",
      "Epoch 357/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1626 - accuracy: 0.9475 - val_loss: 0.0998 - val_accuracy: 0.9694\n",
      "Epoch 358/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1635 - accuracy: 0.9446 - val_loss: 0.0861 - val_accuracy: 0.9755\n",
      "Epoch 359/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1655 - accuracy: 0.9445 - val_loss: 0.0918 - val_accuracy: 0.9703\n",
      "Epoch 360/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1604 - accuracy: 0.9445 - val_loss: 0.0820 - val_accuracy: 0.9764\n",
      "Epoch 361/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1578 - accuracy: 0.9475 - val_loss: 0.1000 - val_accuracy: 0.9703\n",
      "Epoch 362/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1674 - accuracy: 0.9433 - val_loss: 0.0922 - val_accuracy: 0.9729\n",
      "Epoch 363/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.9467 - val_loss: 0.0908 - val_accuracy: 0.9746\n",
      "Epoch 364/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1651 - accuracy: 0.9444 - val_loss: 0.0980 - val_accuracy: 0.9650\n",
      "Epoch 365/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1528 - accuracy: 0.9486 - val_loss: 0.0904 - val_accuracy: 0.9764\n",
      "Epoch 366/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1688 - accuracy: 0.9425 - val_loss: 0.0874 - val_accuracy: 0.9694\n",
      "Epoch 367/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1749 - accuracy: 0.9415 - val_loss: 0.0883 - val_accuracy: 0.9720\n",
      "Epoch 368/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1530 - accuracy: 0.9447 - val_loss: 0.0944 - val_accuracy: 0.9685\n",
      "Epoch 369/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1686 - accuracy: 0.9432 - val_loss: 0.0949 - val_accuracy: 0.9703\n",
      "Epoch 370/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1631 - accuracy: 0.9474 - val_loss: 0.0896 - val_accuracy: 0.9738\n",
      "Epoch 371/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1453 - accuracy: 0.9511 - val_loss: 0.0946 - val_accuracy: 0.9703\n",
      "Epoch 372/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1667 - accuracy: 0.9438 - val_loss: 0.0951 - val_accuracy: 0.9711\n",
      "Epoch 373/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1607 - accuracy: 0.9473 - val_loss: 0.0896 - val_accuracy: 0.9729\n",
      "Epoch 374/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1590 - accuracy: 0.9467 - val_loss: 0.0831 - val_accuracy: 0.9729\n",
      "Epoch 375/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1564 - accuracy: 0.9489 - val_loss: 0.0887 - val_accuracy: 0.9711\n",
      "Epoch 376/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1612 - accuracy: 0.9467 - val_loss: 0.0956 - val_accuracy: 0.9659\n",
      "Epoch 377/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1604 - accuracy: 0.9448 - val_loss: 0.0894 - val_accuracy: 0.9711\n",
      "Epoch 378/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1539 - accuracy: 0.9496 - val_loss: 0.1028 - val_accuracy: 0.9650\n",
      "Epoch 379/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1606 - accuracy: 0.9485 - val_loss: 0.0901 - val_accuracy: 0.9685\n",
      "Epoch 380/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1553 - accuracy: 0.9486 - val_loss: 0.0906 - val_accuracy: 0.9668\n",
      "Epoch 381/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1644 - accuracy: 0.9479 - val_loss: 0.0845 - val_accuracy: 0.9729\n",
      "Epoch 382/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1510 - accuracy: 0.9488 - val_loss: 0.0794 - val_accuracy: 0.9746\n",
      "Epoch 383/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1567 - accuracy: 0.9468 - val_loss: 0.0921 - val_accuracy: 0.9668\n",
      "Epoch 384/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1630 - accuracy: 0.9440 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
      "Epoch 385/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1621 - accuracy: 0.9465 - val_loss: 0.0948 - val_accuracy: 0.9685\n",
      "Epoch 386/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1583 - accuracy: 0.9471 - val_loss: 0.0862 - val_accuracy: 0.9738\n",
      "Epoch 387/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1363 - accuracy: 0.9534 - val_loss: 0.1057 - val_accuracy: 0.9650\n",
      "Epoch 388/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1566 - accuracy: 0.9479 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 389/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1483 - accuracy: 0.9507 - val_loss: 0.0952 - val_accuracy: 0.9668\n",
      "Epoch 390/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1665 - accuracy: 0.9465 - val_loss: 0.0843 - val_accuracy: 0.9711\n",
      "Epoch 391/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1548 - accuracy: 0.9506 - val_loss: 0.0764 - val_accuracy: 0.9781\n",
      "Epoch 392/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1452 - accuracy: 0.9501 - val_loss: 0.0810 - val_accuracy: 0.9755\n",
      "Epoch 393/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1531 - accuracy: 0.9498 - val_loss: 0.0816 - val_accuracy: 0.9764\n",
      "Epoch 394/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1518 - accuracy: 0.9498 - val_loss: 0.0819 - val_accuracy: 0.9781\n",
      "Epoch 395/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1512 - accuracy: 0.9504 - val_loss: 0.0815 - val_accuracy: 0.9738\n",
      "Epoch 396/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1510 - accuracy: 0.9502 - val_loss: 0.0908 - val_accuracy: 0.9703\n",
      "Epoch 397/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1504 - accuracy: 0.9499 - val_loss: 0.0853 - val_accuracy: 0.9755\n",
      "Epoch 398/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1546 - accuracy: 0.9482 - val_loss: 0.0926 - val_accuracy: 0.9720\n",
      "Epoch 399/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1660 - accuracy: 0.9444 - val_loss: 0.0881 - val_accuracy: 0.9729\n",
      "Epoch 400/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1481 - accuracy: 0.9493 - val_loss: 0.1057 - val_accuracy: 0.9668\n",
      "Epoch 401/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1682 - accuracy: 0.9444 - val_loss: 0.0947 - val_accuracy: 0.9720\n",
      "Epoch 402/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1530 - accuracy: 0.9473 - val_loss: 0.0804 - val_accuracy: 0.9694\n",
      "Epoch 403/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1534 - accuracy: 0.9487 - val_loss: 0.0869 - val_accuracy: 0.9720\n",
      "Epoch 404/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1665 - accuracy: 0.9442 - val_loss: 0.0969 - val_accuracy: 0.9738\n",
      "Epoch 405/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1537 - accuracy: 0.9476 - val_loss: 0.0918 - val_accuracy: 0.9676\n",
      "Epoch 406/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1621 - accuracy: 0.9465 - val_loss: 0.0909 - val_accuracy: 0.9729\n",
      "Epoch 407/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1576 - accuracy: 0.9485 - val_loss: 0.0752 - val_accuracy: 0.9781\n",
      "Epoch 408/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1450 - accuracy: 0.9523 - val_loss: 0.0799 - val_accuracy: 0.9781\n",
      "Epoch 409/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1492 - accuracy: 0.9494 - val_loss: 0.0965 - val_accuracy: 0.9668\n",
      "Epoch 410/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1524 - accuracy: 0.9471 - val_loss: 0.0890 - val_accuracy: 0.9685\n",
      "Epoch 411/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1646 - accuracy: 0.9449 - val_loss: 0.0773 - val_accuracy: 0.9773\n",
      "Epoch 412/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1431 - accuracy: 0.9516 - val_loss: 0.0910 - val_accuracy: 0.9729\n",
      "Epoch 413/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1483 - accuracy: 0.9491 - val_loss: 0.0993 - val_accuracy: 0.9694\n",
      "Epoch 414/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1658 - accuracy: 0.9454 - val_loss: 0.0783 - val_accuracy: 0.9773\n",
      "Epoch 415/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1429 - accuracy: 0.9541 - val_loss: 0.0799 - val_accuracy: 0.9781\n",
      "Epoch 416/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1534 - accuracy: 0.9520 - val_loss: 0.0829 - val_accuracy: 0.9790\n",
      "Epoch 417/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1481 - accuracy: 0.9486 - val_loss: 0.0808 - val_accuracy: 0.9746\n",
      "Epoch 418/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1529 - accuracy: 0.9463 - val_loss: 0.0968 - val_accuracy: 0.9720\n",
      "Epoch 419/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1541 - accuracy: 0.9496 - val_loss: 0.0878 - val_accuracy: 0.9738\n",
      "Epoch 420/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1526 - accuracy: 0.9489 - val_loss: 0.0831 - val_accuracy: 0.9755\n",
      "Epoch 421/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1550 - accuracy: 0.9490 - val_loss: 0.0906 - val_accuracy: 0.9703\n",
      "Epoch 422/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9509 - val_loss: 0.0862 - val_accuracy: 0.9720\n",
      "Epoch 423/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1572 - accuracy: 0.9492 - val_loss: 0.0826 - val_accuracy: 0.9720\n",
      "Epoch 424/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1457 - accuracy: 0.9509 - val_loss: 0.0943 - val_accuracy: 0.9720\n",
      "Epoch 425/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1509 - accuracy: 0.9500 - val_loss: 0.0903 - val_accuracy: 0.9703\n",
      "Epoch 426/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1418 - accuracy: 0.9530 - val_loss: 0.0850 - val_accuracy: 0.9729\n",
      "Epoch 427/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1623 - accuracy: 0.9469 - val_loss: 0.0909 - val_accuracy: 0.9711\n",
      "Epoch 428/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1498 - accuracy: 0.9520 - val_loss: 0.0886 - val_accuracy: 0.9720\n",
      "Epoch 429/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1515 - accuracy: 0.9506 - val_loss: 0.0962 - val_accuracy: 0.9685\n",
      "Epoch 430/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1574 - accuracy: 0.9465 - val_loss: 0.0905 - val_accuracy: 0.9711\n",
      "Epoch 431/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1570 - accuracy: 0.9488 - val_loss: 0.0901 - val_accuracy: 0.9668\n",
      "Epoch 432/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1449 - accuracy: 0.9516 - val_loss: 0.0906 - val_accuracy: 0.9703\n",
      "Epoch 433/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1518 - accuracy: 0.9488 - val_loss: 0.0841 - val_accuracy: 0.9711\n",
      "Epoch 434/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1664 - accuracy: 0.9442 - val_loss: 0.0841 - val_accuracy: 0.9694\n",
      "Epoch 435/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1381 - accuracy: 0.9544 - val_loss: 0.0887 - val_accuracy: 0.9738\n",
      "Epoch 436/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1482 - accuracy: 0.9484 - val_loss: 0.0834 - val_accuracy: 0.9720\n",
      "Epoch 437/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1546 - accuracy: 0.9475 - val_loss: 0.0829 - val_accuracy: 0.9729\n",
      "Epoch 438/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1615 - accuracy: 0.9468 - val_loss: 0.0922 - val_accuracy: 0.9676\n",
      "Epoch 439/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1588 - accuracy: 0.9484 - val_loss: 0.0940 - val_accuracy: 0.9720\n",
      "Epoch 440/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1488 - accuracy: 0.9493 - val_loss: 0.0868 - val_accuracy: 0.9711\n",
      "Epoch 441/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1459 - accuracy: 0.9491 - val_loss: 0.0844 - val_accuracy: 0.9746\n",
      "Epoch 442/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1448 - accuracy: 0.9517 - val_loss: 0.0783 - val_accuracy: 0.9764\n",
      "Epoch 443/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1436 - accuracy: 0.9524 - val_loss: 0.0816 - val_accuracy: 0.9738\n",
      "Epoch 444/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9513 - val_loss: 0.0856 - val_accuracy: 0.9738\n",
      "Epoch 445/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1484 - accuracy: 0.9496 - val_loss: 0.0909 - val_accuracy: 0.9703\n",
      "Epoch 446/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1478 - accuracy: 0.9506 - val_loss: 0.0879 - val_accuracy: 0.9764\n",
      "Epoch 447/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1413 - accuracy: 0.9520 - val_loss: 0.0874 - val_accuracy: 0.9685\n",
      "Epoch 448/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1497 - accuracy: 0.9500 - val_loss: 0.0901 - val_accuracy: 0.9738\n",
      "Epoch 449/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1665 - accuracy: 0.9447 - val_loss: 0.0834 - val_accuracy: 0.9746\n",
      "Epoch 450/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1434 - accuracy: 0.9515 - val_loss: 0.0851 - val_accuracy: 0.9668\n",
      "Epoch 451/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1417 - accuracy: 0.9533 - val_loss: 0.0725 - val_accuracy: 0.9781\n",
      "Epoch 452/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1528 - accuracy: 0.9511 - val_loss: 0.0826 - val_accuracy: 0.9720\n",
      "Epoch 453/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1680 - accuracy: 0.9448 - val_loss: 0.0839 - val_accuracy: 0.9729\n",
      "Epoch 454/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1603 - accuracy: 0.9478 - val_loss: 0.0865 - val_accuracy: 0.9729\n",
      "Epoch 455/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9495 - val_loss: 0.0972 - val_accuracy: 0.9668\n",
      "Epoch 456/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1417 - accuracy: 0.9547 - val_loss: 0.0860 - val_accuracy: 0.9746\n",
      "Epoch 457/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1395 - accuracy: 0.9520 - val_loss: 0.0931 - val_accuracy: 0.9676\n",
      "Epoch 458/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1456 - accuracy: 0.9499 - val_loss: 0.0942 - val_accuracy: 0.9711\n",
      "Epoch 459/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1494 - accuracy: 0.9494 - val_loss: 0.0823 - val_accuracy: 0.9755\n",
      "Epoch 460/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1387 - accuracy: 0.9537 - val_loss: 0.0982 - val_accuracy: 0.9729\n",
      "Epoch 461/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1666 - accuracy: 0.9440 - val_loss: 0.0920 - val_accuracy: 0.9720\n",
      "Epoch 462/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1505 - accuracy: 0.9510 - val_loss: 0.0866 - val_accuracy: 0.9738\n",
      "Epoch 463/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1469 - accuracy: 0.9511 - val_loss: 0.0952 - val_accuracy: 0.9711\n",
      "Epoch 464/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1459 - accuracy: 0.9508 - val_loss: 0.0899 - val_accuracy: 0.9703\n",
      "Epoch 465/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1305 - accuracy: 0.9548 - val_loss: 0.0949 - val_accuracy: 0.9711\n",
      "Epoch 466/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1552 - accuracy: 0.9485 - val_loss: 0.0928 - val_accuracy: 0.9685\n",
      "Epoch 467/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1476 - accuracy: 0.9501 - val_loss: 0.0926 - val_accuracy: 0.9711\n",
      "Epoch 468/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1397 - accuracy: 0.9539 - val_loss: 0.0804 - val_accuracy: 0.9773\n",
      "Epoch 469/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1443 - accuracy: 0.9510 - val_loss: 0.0851 - val_accuracy: 0.9764\n",
      "Epoch 470/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1340 - accuracy: 0.9549 - val_loss: 0.0889 - val_accuracy: 0.9729\n",
      "Epoch 471/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1477 - accuracy: 0.9492 - val_loss: 0.1095 - val_accuracy: 0.9685\n",
      "Epoch 472/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1387 - accuracy: 0.9527 - val_loss: 0.0785 - val_accuracy: 0.9755\n",
      "Epoch 473/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9508 - val_loss: 0.0951 - val_accuracy: 0.9738\n",
      "Epoch 474/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1456 - accuracy: 0.9524 - val_loss: 0.0967 - val_accuracy: 0.9703\n",
      "Epoch 475/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1417 - accuracy: 0.9539 - val_loss: 0.0889 - val_accuracy: 0.9720\n",
      "Epoch 476/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1434 - accuracy: 0.9519 - val_loss: 0.0909 - val_accuracy: 0.9676\n",
      "Epoch 477/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1391 - accuracy: 0.9549 - val_loss: 0.0773 - val_accuracy: 0.9738\n",
      "Epoch 478/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1299 - accuracy: 0.9564 - val_loss: 0.0842 - val_accuracy: 0.9746\n",
      "Epoch 479/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1410 - accuracy: 0.9550 - val_loss: 0.0881 - val_accuracy: 0.9738\n",
      "Epoch 480/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1485 - accuracy: 0.9502 - val_loss: 0.0754 - val_accuracy: 0.9720\n",
      "Epoch 481/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1428 - accuracy: 0.9519 - val_loss: 0.0895 - val_accuracy: 0.9711\n",
      "Epoch 482/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1506 - accuracy: 0.9494 - val_loss: 0.0818 - val_accuracy: 0.9755\n",
      "Epoch 483/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1445 - accuracy: 0.9532 - val_loss: 0.0836 - val_accuracy: 0.9755\n",
      "Epoch 484/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1365 - accuracy: 0.9536 - val_loss: 0.0815 - val_accuracy: 0.9703\n",
      "Epoch 485/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1402 - accuracy: 0.9514 - val_loss: 0.0799 - val_accuracy: 0.9738\n",
      "Epoch 486/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1376 - accuracy: 0.9531 - val_loss: 0.0847 - val_accuracy: 0.9764\n",
      "Epoch 487/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1440 - accuracy: 0.9507 - val_loss: 0.0804 - val_accuracy: 0.9773\n",
      "Epoch 488/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1342 - accuracy: 0.9541 - val_loss: 0.0792 - val_accuracy: 0.9755\n",
      "Epoch 489/1000\n",
      "161/161 [==============================] - 2s 9ms/step - loss: 0.1457 - accuracy: 0.9520 - val_loss: 0.0868 - val_accuracy: 0.9694\n",
      "Epoch 490/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1459 - accuracy: 0.9544 - val_loss: 0.0895 - val_accuracy: 0.9694\n",
      "Epoch 491/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1383 - accuracy: 0.9550 - val_loss: 0.0770 - val_accuracy: 0.9720\n",
      "Epoch 492/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1490 - accuracy: 0.9517 - val_loss: 0.0822 - val_accuracy: 0.9694\n",
      "Epoch 493/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1524 - accuracy: 0.9508 - val_loss: 0.0725 - val_accuracy: 0.9764\n",
      "Epoch 494/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1455 - accuracy: 0.9522 - val_loss: 0.0767 - val_accuracy: 0.9738\n",
      "Epoch 495/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1482 - accuracy: 0.9519 - val_loss: 0.0736 - val_accuracy: 0.9773\n",
      "Epoch 496/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1485 - accuracy: 0.9535 - val_loss: 0.0805 - val_accuracy: 0.9773\n",
      "Epoch 497/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1505 - accuracy: 0.9505 - val_loss: 0.0736 - val_accuracy: 0.9790\n",
      "Epoch 498/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1442 - accuracy: 0.9510 - val_loss: 0.0814 - val_accuracy: 0.9746\n",
      "Epoch 499/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1527 - accuracy: 0.9496 - val_loss: 0.0820 - val_accuracy: 0.9720\n",
      "Epoch 500/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1510 - accuracy: 0.9482 - val_loss: 0.0804 - val_accuracy: 0.9764\n",
      "Epoch 501/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1323 - accuracy: 0.9565 - val_loss: 0.0767 - val_accuracy: 0.9755\n",
      "Epoch 502/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1396 - accuracy: 0.9525 - val_loss: 0.0787 - val_accuracy: 0.9755\n",
      "Epoch 503/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9492 - val_loss: 0.0796 - val_accuracy: 0.9781\n",
      "Epoch 504/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1446 - accuracy: 0.9518 - val_loss: 0.0736 - val_accuracy: 0.9799\n",
      "Epoch 505/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1365 - accuracy: 0.9553 - val_loss: 0.0763 - val_accuracy: 0.9773\n",
      "Epoch 506/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1444 - accuracy: 0.9527 - val_loss: 0.0810 - val_accuracy: 0.9703\n",
      "Epoch 507/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1411 - accuracy: 0.9536 - val_loss: 0.0817 - val_accuracy: 0.9711\n",
      "Epoch 508/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1484 - accuracy: 0.9500 - val_loss: 0.0819 - val_accuracy: 0.9738\n",
      "Epoch 509/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1359 - accuracy: 0.9558 - val_loss: 0.0887 - val_accuracy: 0.9720\n",
      "Epoch 510/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1312 - accuracy: 0.9554 - val_loss: 0.0859 - val_accuracy: 0.9720\n",
      "Epoch 511/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1421 - accuracy: 0.9524 - val_loss: 0.0833 - val_accuracy: 0.9729\n",
      "Epoch 512/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1509 - accuracy: 0.9503 - val_loss: 0.0811 - val_accuracy: 0.9746\n",
      "Epoch 513/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1415 - accuracy: 0.9535 - val_loss: 0.0827 - val_accuracy: 0.9738\n",
      "Epoch 514/1000\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1373 - accuracy: 0.9556 - val_loss: 0.0754 - val_accuracy: 0.9746\n",
      "Epoch 515/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1344 - accuracy: 0.9547 - val_loss: 0.0713 - val_accuracy: 0.9720\n",
      "Epoch 516/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1456 - accuracy: 0.9524 - val_loss: 0.0822 - val_accuracy: 0.9711\n",
      "Epoch 517/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1468 - accuracy: 0.9508 - val_loss: 0.0739 - val_accuracy: 0.9773\n",
      "Epoch 518/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1409 - accuracy: 0.9547 - val_loss: 0.0954 - val_accuracy: 0.9676\n",
      "Epoch 519/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1307 - accuracy: 0.9526 - val_loss: 0.0779 - val_accuracy: 0.9729\n",
      "Epoch 520/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1402 - accuracy: 0.9550 - val_loss: 0.0826 - val_accuracy: 0.9755\n",
      "Epoch 521/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1548 - accuracy: 0.9509 - val_loss: 0.0773 - val_accuracy: 0.9764\n",
      "Epoch 522/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1335 - accuracy: 0.9555 - val_loss: 0.0866 - val_accuracy: 0.9694\n",
      "Epoch 523/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1364 - accuracy: 0.9558 - val_loss: 0.0806 - val_accuracy: 0.9729\n",
      "Epoch 524/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1372 - accuracy: 0.9539 - val_loss: 0.0790 - val_accuracy: 0.9764\n",
      "Epoch 525/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1474 - accuracy: 0.9526 - val_loss: 0.0825 - val_accuracy: 0.9729\n",
      "Epoch 526/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1377 - accuracy: 0.9535 - val_loss: 0.0836 - val_accuracy: 0.9729\n",
      "Epoch 527/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1385 - accuracy: 0.9527 - val_loss: 0.0825 - val_accuracy: 0.9781\n",
      "Epoch 528/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1472 - accuracy: 0.9516 - val_loss: 0.0775 - val_accuracy: 0.9764\n",
      "Epoch 529/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1291 - accuracy: 0.9551 - val_loss: 0.0839 - val_accuracy: 0.9738\n",
      "Epoch 530/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1558 - accuracy: 0.9495 - val_loss: 0.0806 - val_accuracy: 0.9746\n",
      "Epoch 531/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1455 - accuracy: 0.9521 - val_loss: 0.0888 - val_accuracy: 0.9659\n",
      "Epoch 532/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1412 - accuracy: 0.9520 - val_loss: 0.0756 - val_accuracy: 0.9738\n",
      "Epoch 533/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1408 - accuracy: 0.9543 - val_loss: 0.0715 - val_accuracy: 0.9764\n",
      "Epoch 534/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1354 - accuracy: 0.9519 - val_loss: 0.0833 - val_accuracy: 0.9703\n",
      "Epoch 535/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1335 - accuracy: 0.9546 - val_loss: 0.0910 - val_accuracy: 0.9711\n",
      "Epoch 536/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1369 - accuracy: 0.9545 - val_loss: 0.0832 - val_accuracy: 0.9694\n",
      "Epoch 537/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1442 - accuracy: 0.9508 - val_loss: 0.0922 - val_accuracy: 0.9703\n",
      "Epoch 538/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1290 - accuracy: 0.9587 - val_loss: 0.0765 - val_accuracy: 0.9711\n",
      "Epoch 539/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9530 - val_loss: 0.0819 - val_accuracy: 0.9711\n",
      "Epoch 540/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1451 - accuracy: 0.9521 - val_loss: 0.0773 - val_accuracy: 0.9729\n",
      "Epoch 541/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1347 - accuracy: 0.9544 - val_loss: 0.0801 - val_accuracy: 0.9738\n",
      "Epoch 542/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9595 - val_loss: 0.0858 - val_accuracy: 0.9711\n",
      "Epoch 543/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1293 - accuracy: 0.9567 - val_loss: 0.0781 - val_accuracy: 0.9755\n",
      "Epoch 544/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1373 - accuracy: 0.9547 - val_loss: 0.0841 - val_accuracy: 0.9764\n",
      "Epoch 545/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1306 - accuracy: 0.9570 - val_loss: 0.0720 - val_accuracy: 0.9773\n",
      "Epoch 546/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1339 - accuracy: 0.9545 - val_loss: 0.0860 - val_accuracy: 0.9694\n",
      "Epoch 547/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1352 - accuracy: 0.9550 - val_loss: 0.0775 - val_accuracy: 0.9755\n",
      "Epoch 548/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1416 - accuracy: 0.9520 - val_loss: 0.0844 - val_accuracy: 0.9729\n",
      "Epoch 549/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1431 - accuracy: 0.9537 - val_loss: 0.0801 - val_accuracy: 0.9729\n",
      "Epoch 550/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1521 - accuracy: 0.9520 - val_loss: 0.0702 - val_accuracy: 0.9764\n",
      "Epoch 551/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1343 - accuracy: 0.9537 - val_loss: 0.0801 - val_accuracy: 0.9746\n",
      "Epoch 552/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1396 - accuracy: 0.9531 - val_loss: 0.0782 - val_accuracy: 0.9703\n",
      "Epoch 553/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1368 - accuracy: 0.9553 - val_loss: 0.0762 - val_accuracy: 0.9746\n",
      "Epoch 554/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9552 - val_loss: 0.0955 - val_accuracy: 0.9676\n",
      "Epoch 555/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1439 - accuracy: 0.9501 - val_loss: 0.0879 - val_accuracy: 0.9729\n",
      "Epoch 556/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1331 - accuracy: 0.9559 - val_loss: 0.0765 - val_accuracy: 0.9746\n",
      "Epoch 557/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9585 - val_loss: 0.0832 - val_accuracy: 0.9764\n",
      "Epoch 558/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1311 - accuracy: 0.9553 - val_loss: 0.0761 - val_accuracy: 0.9773\n",
      "Epoch 559/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1514 - accuracy: 0.9519 - val_loss: 0.0757 - val_accuracy: 0.9755\n",
      "Epoch 560/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1484 - accuracy: 0.9534 - val_loss: 0.0682 - val_accuracy: 0.9764\n",
      "Epoch 561/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1346 - accuracy: 0.9557 - val_loss: 0.0770 - val_accuracy: 0.9764\n",
      "Epoch 562/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1485 - accuracy: 0.9504 - val_loss: 0.0838 - val_accuracy: 0.9711\n",
      "Epoch 563/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1448 - accuracy: 0.9512 - val_loss: 0.0880 - val_accuracy: 0.9694\n",
      "Epoch 564/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1346 - accuracy: 0.9557 - val_loss: 0.0858 - val_accuracy: 0.9685\n",
      "Epoch 565/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1377 - accuracy: 0.9548 - val_loss: 0.0814 - val_accuracy: 0.9738\n",
      "Epoch 566/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1484 - accuracy: 0.9523 - val_loss: 0.0758 - val_accuracy: 0.9755\n",
      "Epoch 567/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9546 - val_loss: 0.0752 - val_accuracy: 0.9764\n",
      "Epoch 568/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1300 - accuracy: 0.9569 - val_loss: 0.0761 - val_accuracy: 0.9720\n",
      "Epoch 569/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1405 - accuracy: 0.9530 - val_loss: 0.0968 - val_accuracy: 0.9720\n",
      "Epoch 570/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1424 - accuracy: 0.9538 - val_loss: 0.0809 - val_accuracy: 0.9773\n",
      "Epoch 571/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1360 - accuracy: 0.9548 - val_loss: 0.0757 - val_accuracy: 0.9746\n",
      "Epoch 572/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1381 - accuracy: 0.9548 - val_loss: 0.0796 - val_accuracy: 0.9711\n",
      "Epoch 573/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1388 - accuracy: 0.9530 - val_loss: 0.0789 - val_accuracy: 0.9729\n",
      "Epoch 574/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1380 - accuracy: 0.9558 - val_loss: 0.0778 - val_accuracy: 0.9755\n",
      "Epoch 575/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1354 - accuracy: 0.9545 - val_loss: 0.0838 - val_accuracy: 0.9703\n",
      "Epoch 576/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1439 - accuracy: 0.9533 - val_loss: 0.0691 - val_accuracy: 0.9729\n",
      "Epoch 577/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1339 - accuracy: 0.9549 - val_loss: 0.0875 - val_accuracy: 0.9720\n",
      "Epoch 578/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1249 - accuracy: 0.9567 - val_loss: 0.0877 - val_accuracy: 0.9720\n",
      "Epoch 579/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1324 - accuracy: 0.9561 - val_loss: 0.0692 - val_accuracy: 0.9790\n",
      "Epoch 580/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1443 - accuracy: 0.9509 - val_loss: 0.0743 - val_accuracy: 0.9746\n",
      "Epoch 581/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1343 - accuracy: 0.9550 - val_loss: 0.0869 - val_accuracy: 0.9711\n",
      "Epoch 582/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1317 - accuracy: 0.9559 - val_loss: 0.0719 - val_accuracy: 0.9738\n",
      "Epoch 583/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1561 - accuracy: 0.9520 - val_loss: 0.0609 - val_accuracy: 0.9808\n",
      "Epoch 584/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1348 - accuracy: 0.9573 - val_loss: 0.0806 - val_accuracy: 0.9738\n",
      "Epoch 585/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1390 - accuracy: 0.9523 - val_loss: 0.0784 - val_accuracy: 0.9781\n",
      "Epoch 586/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9518 - val_loss: 0.0707 - val_accuracy: 0.9773\n",
      "Epoch 587/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1385 - accuracy: 0.9534 - val_loss: 0.0763 - val_accuracy: 0.9764\n",
      "Epoch 588/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9544 - val_loss: 0.0774 - val_accuracy: 0.9738\n",
      "Epoch 589/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1299 - accuracy: 0.9573 - val_loss: 0.0754 - val_accuracy: 0.9799\n",
      "Epoch 590/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1302 - accuracy: 0.9567 - val_loss: 0.0846 - val_accuracy: 0.9755\n",
      "Epoch 591/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1383 - accuracy: 0.9554 - val_loss: 0.0816 - val_accuracy: 0.9711\n",
      "Epoch 592/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1344 - accuracy: 0.9550 - val_loss: 0.0856 - val_accuracy: 0.9720\n",
      "Epoch 593/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1310 - accuracy: 0.9577 - val_loss: 0.0799 - val_accuracy: 0.9764\n",
      "Epoch 594/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1423 - accuracy: 0.9541 - val_loss: 0.0845 - val_accuracy: 0.9773\n",
      "Epoch 595/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1296 - accuracy: 0.9591 - val_loss: 0.0819 - val_accuracy: 0.9729\n",
      "Epoch 596/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9574 - val_loss: 0.0737 - val_accuracy: 0.9790\n",
      "Epoch 597/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1451 - accuracy: 0.9529 - val_loss: 0.0734 - val_accuracy: 0.9755\n",
      "Epoch 598/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1352 - accuracy: 0.9548 - val_loss: 0.0731 - val_accuracy: 0.9764\n",
      "Epoch 599/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1446 - accuracy: 0.9522 - val_loss: 0.0821 - val_accuracy: 0.9703\n",
      "Epoch 600/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1322 - accuracy: 0.9570 - val_loss: 0.0802 - val_accuracy: 0.9729\n",
      "Epoch 601/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1419 - accuracy: 0.9538 - val_loss: 0.0760 - val_accuracy: 0.9711\n",
      "Epoch 602/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1407 - accuracy: 0.9531 - val_loss: 0.0766 - val_accuracy: 0.9720\n",
      "Epoch 603/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1382 - accuracy: 0.9533 - val_loss: 0.0839 - val_accuracy: 0.9711\n",
      "Epoch 604/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1249 - accuracy: 0.9593 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
      "Epoch 605/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1285 - accuracy: 0.9571 - val_loss: 0.0774 - val_accuracy: 0.9720\n",
      "Epoch 606/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1380 - accuracy: 0.9546 - val_loss: 0.0672 - val_accuracy: 0.9799\n",
      "Epoch 607/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1226 - accuracy: 0.9599 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
      "Epoch 608/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1330 - accuracy: 0.9557 - val_loss: 0.0794 - val_accuracy: 0.9720\n",
      "Epoch 609/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1293 - accuracy: 0.9578 - val_loss: 0.0803 - val_accuracy: 0.9711\n",
      "Epoch 610/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1248 - accuracy: 0.9591 - val_loss: 0.0924 - val_accuracy: 0.9746\n",
      "Epoch 611/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1384 - accuracy: 0.9515 - val_loss: 0.0802 - val_accuracy: 0.9764\n",
      "Epoch 612/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1424 - accuracy: 0.9518 - val_loss: 0.0782 - val_accuracy: 0.9729\n",
      "Epoch 613/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9516 - val_loss: 0.0732 - val_accuracy: 0.9781\n",
      "Epoch 614/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1450 - accuracy: 0.9535 - val_loss: 0.0789 - val_accuracy: 0.9720\n",
      "Epoch 615/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1329 - accuracy: 0.9577 - val_loss: 0.0863 - val_accuracy: 0.9720\n",
      "Epoch 616/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1351 - accuracy: 0.9541 - val_loss: 0.0755 - val_accuracy: 0.9738\n",
      "Epoch 617/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1250 - accuracy: 0.9590 - val_loss: 0.0781 - val_accuracy: 0.9781\n",
      "Epoch 618/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1362 - accuracy: 0.9566 - val_loss: 0.0817 - val_accuracy: 0.9703\n",
      "Epoch 619/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1407 - accuracy: 0.9520 - val_loss: 0.0684 - val_accuracy: 0.9790\n",
      "Epoch 620/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1361 - accuracy: 0.9574 - val_loss: 0.0811 - val_accuracy: 0.9729\n",
      "Epoch 621/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1189 - accuracy: 0.9580 - val_loss: 0.0853 - val_accuracy: 0.9711\n",
      "Epoch 622/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9548 - val_loss: 0.0880 - val_accuracy: 0.9755\n",
      "Epoch 623/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1359 - accuracy: 0.9548 - val_loss: 0.0705 - val_accuracy: 0.9746\n",
      "Epoch 624/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1379 - accuracy: 0.9558 - val_loss: 0.0756 - val_accuracy: 0.9746\n",
      "Epoch 625/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1279 - accuracy: 0.9565 - val_loss: 0.0779 - val_accuracy: 0.9746\n",
      "Epoch 626/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9582 - val_loss: 0.0836 - val_accuracy: 0.9720\n",
      "Epoch 627/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1398 - accuracy: 0.9519 - val_loss: 0.0785 - val_accuracy: 0.9738\n",
      "Epoch 628/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1388 - accuracy: 0.9561 - val_loss: 0.0782 - val_accuracy: 0.9738\n",
      "Epoch 629/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1322 - accuracy: 0.9550 - val_loss: 0.0884 - val_accuracy: 0.9755\n",
      "Epoch 630/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1433 - accuracy: 0.9524 - val_loss: 0.0776 - val_accuracy: 0.9685\n",
      "Epoch 631/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1300 - accuracy: 0.9590 - val_loss: 0.0919 - val_accuracy: 0.9711\n",
      "Epoch 632/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1348 - accuracy: 0.9581 - val_loss: 0.0773 - val_accuracy: 0.9755\n",
      "Epoch 633/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1301 - accuracy: 0.9572 - val_loss: 0.0825 - val_accuracy: 0.9755\n",
      "Epoch 634/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.9597 - val_loss: 0.1042 - val_accuracy: 0.9694\n",
      "Epoch 635/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1344 - accuracy: 0.9552 - val_loss: 0.0719 - val_accuracy: 0.9764\n",
      "Epoch 636/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1189 - accuracy: 0.9610 - val_loss: 0.0831 - val_accuracy: 0.9746\n",
      "Epoch 637/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1218 - accuracy: 0.9602 - val_loss: 0.0711 - val_accuracy: 0.9799\n",
      "Epoch 638/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1286 - accuracy: 0.9570 - val_loss: 0.0735 - val_accuracy: 0.9799\n",
      "Epoch 639/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1406 - accuracy: 0.9539 - val_loss: 0.0825 - val_accuracy: 0.9738\n",
      "Epoch 640/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1323 - accuracy: 0.9563 - val_loss: 0.0752 - val_accuracy: 0.9746\n",
      "Epoch 641/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.9581 - val_loss: 0.0744 - val_accuracy: 0.9764\n",
      "Epoch 642/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1211 - accuracy: 0.9592 - val_loss: 0.0721 - val_accuracy: 0.9790\n",
      "Epoch 643/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.0727 - val_accuracy: 0.9764\n",
      "Epoch 644/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1388 - accuracy: 0.9550 - val_loss: 0.0775 - val_accuracy: 0.9738\n",
      "Epoch 645/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1278 - accuracy: 0.9577 - val_loss: 0.0738 - val_accuracy: 0.9746\n",
      "Epoch 646/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9584 - val_loss: 0.0751 - val_accuracy: 0.9746\n",
      "Epoch 647/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1380 - accuracy: 0.9547 - val_loss: 0.0756 - val_accuracy: 0.9755\n",
      "Epoch 648/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1284 - accuracy: 0.9586 - val_loss: 0.0859 - val_accuracy: 0.9729\n",
      "Epoch 649/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1370 - accuracy: 0.9555 - val_loss: 0.0859 - val_accuracy: 0.9729\n",
      "Epoch 650/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1378 - accuracy: 0.9544 - val_loss: 0.0818 - val_accuracy: 0.9711\n",
      "Epoch 651/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1226 - accuracy: 0.9594 - val_loss: 0.0882 - val_accuracy: 0.9729\n",
      "Epoch 652/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1383 - accuracy: 0.9559 - val_loss: 0.0763 - val_accuracy: 0.9790\n",
      "Epoch 653/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1332 - accuracy: 0.9562 - val_loss: 0.0826 - val_accuracy: 0.9746\n",
      "Epoch 654/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1399 - accuracy: 0.9541 - val_loss: 0.0843 - val_accuracy: 0.9773\n",
      "Epoch 655/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1311 - accuracy: 0.9563 - val_loss: 0.0908 - val_accuracy: 0.9659\n",
      "Epoch 656/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9579 - val_loss: 0.0736 - val_accuracy: 0.9755\n",
      "Epoch 657/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1215 - accuracy: 0.9592 - val_loss: 0.0810 - val_accuracy: 0.9746\n",
      "Epoch 658/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1292 - accuracy: 0.9560 - val_loss: 0.0759 - val_accuracy: 0.9729\n",
      "Epoch 659/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9582 - val_loss: 0.0812 - val_accuracy: 0.9738\n",
      "Epoch 660/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1276 - accuracy: 0.9590 - val_loss: 0.0845 - val_accuracy: 0.9738\n",
      "Epoch 661/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1464 - accuracy: 0.9518 - val_loss: 0.0767 - val_accuracy: 0.9781\n",
      "Epoch 662/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9584 - val_loss: 0.0718 - val_accuracy: 0.9764\n",
      "Epoch 663/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1253 - accuracy: 0.9591 - val_loss: 0.0893 - val_accuracy: 0.9781\n",
      "Epoch 664/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1269 - accuracy: 0.9568 - val_loss: 0.0705 - val_accuracy: 0.9755\n",
      "Epoch 665/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1300 - accuracy: 0.9576 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
      "Epoch 666/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1251 - accuracy: 0.9606 - val_loss: 0.0745 - val_accuracy: 0.9781\n",
      "Epoch 667/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1374 - accuracy: 0.9538 - val_loss: 0.0831 - val_accuracy: 0.9746\n",
      "Epoch 668/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1269 - accuracy: 0.9600 - val_loss: 0.0818 - val_accuracy: 0.9746\n",
      "Epoch 669/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1232 - accuracy: 0.9603 - val_loss: 0.0725 - val_accuracy: 0.9764\n",
      "Epoch 670/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1353 - accuracy: 0.9567 - val_loss: 0.0768 - val_accuracy: 0.9746\n",
      "Epoch 671/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1352 - accuracy: 0.9548 - val_loss: 0.0750 - val_accuracy: 0.9764\n",
      "Epoch 672/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1238 - accuracy: 0.9594 - val_loss: 0.0732 - val_accuracy: 0.9764\n",
      "Epoch 673/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1326 - accuracy: 0.9573 - val_loss: 0.0759 - val_accuracy: 0.9755\n",
      "Epoch 674/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9589 - val_loss: 0.0785 - val_accuracy: 0.9773\n",
      "Epoch 675/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1261 - accuracy: 0.9586 - val_loss: 0.0708 - val_accuracy: 0.9781\n",
      "Epoch 676/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1147 - accuracy: 0.9612 - val_loss: 0.0864 - val_accuracy: 0.9746\n",
      "Epoch 677/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1321 - accuracy: 0.9572 - val_loss: 0.0731 - val_accuracy: 0.9773\n",
      "Epoch 678/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1319 - accuracy: 0.9578 - val_loss: 0.0826 - val_accuracy: 0.9668\n",
      "Epoch 679/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1332 - accuracy: 0.9559 - val_loss: 0.0689 - val_accuracy: 0.9790\n",
      "Epoch 680/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1310 - accuracy: 0.9566 - val_loss: 0.0688 - val_accuracy: 0.9764\n",
      "Epoch 681/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1153 - accuracy: 0.9626 - val_loss: 0.0762 - val_accuracy: 0.9738\n",
      "Epoch 682/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1240 - accuracy: 0.9591 - val_loss: 0.0758 - val_accuracy: 0.9773\n",
      "Epoch 683/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1396 - accuracy: 0.9552 - val_loss: 0.0870 - val_accuracy: 0.9694\n",
      "Epoch 684/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9594 - val_loss: 0.0765 - val_accuracy: 0.9746\n",
      "Epoch 685/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1273 - accuracy: 0.9574 - val_loss: 0.0749 - val_accuracy: 0.9790\n",
      "Epoch 686/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1194 - accuracy: 0.9615 - val_loss: 0.0728 - val_accuracy: 0.9773\n",
      "Epoch 687/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1202 - accuracy: 0.9606 - val_loss: 0.0667 - val_accuracy: 0.9755\n",
      "Epoch 688/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1272 - accuracy: 0.9573 - val_loss: 0.0814 - val_accuracy: 0.9790\n",
      "Epoch 689/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1360 - accuracy: 0.9569 - val_loss: 0.0864 - val_accuracy: 0.9755\n",
      "Epoch 690/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1361 - accuracy: 0.9544 - val_loss: 0.0798 - val_accuracy: 0.9720\n",
      "Epoch 691/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1198 - accuracy: 0.9614 - val_loss: 0.0861 - val_accuracy: 0.9720\n",
      "Epoch 692/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1471 - accuracy: 0.9509 - val_loss: 0.0839 - val_accuracy: 0.9720\n",
      "Epoch 693/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1274 - accuracy: 0.9596 - val_loss: 0.0702 - val_accuracy: 0.9764\n",
      "Epoch 694/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1359 - accuracy: 0.9549 - val_loss: 0.0711 - val_accuracy: 0.9764\n",
      "Epoch 695/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1184 - accuracy: 0.9606 - val_loss: 0.0765 - val_accuracy: 0.9738\n",
      "Epoch 696/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1290 - accuracy: 0.9571 - val_loss: 0.0866 - val_accuracy: 0.9729\n",
      "Epoch 697/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1378 - accuracy: 0.9570 - val_loss: 0.0738 - val_accuracy: 0.9755\n",
      "Epoch 698/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1198 - accuracy: 0.9620 - val_loss: 0.0861 - val_accuracy: 0.9738\n",
      "Epoch 699/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1281 - accuracy: 0.9591 - val_loss: 0.0715 - val_accuracy: 0.9764\n",
      "Epoch 700/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1294 - accuracy: 0.9577 - val_loss: 0.0777 - val_accuracy: 0.9781\n",
      "Epoch 701/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1373 - accuracy: 0.9555 - val_loss: 0.0779 - val_accuracy: 0.9729\n",
      "Epoch 702/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1255 - accuracy: 0.9583 - val_loss: 0.0888 - val_accuracy: 0.9729\n",
      "Epoch 703/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1283 - accuracy: 0.9573 - val_loss: 0.0682 - val_accuracy: 0.9773\n",
      "Epoch 704/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1202 - accuracy: 0.9626 - val_loss: 0.0742 - val_accuracy: 0.9773\n",
      "Epoch 705/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1346 - accuracy: 0.9550 - val_loss: 0.0830 - val_accuracy: 0.9755\n",
      "Epoch 706/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1347 - accuracy: 0.9548 - val_loss: 0.0734 - val_accuracy: 0.9773\n",
      "Epoch 707/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1280 - accuracy: 0.9603 - val_loss: 0.0695 - val_accuracy: 0.9790\n",
      "Epoch 708/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1160 - accuracy: 0.9615 - val_loss: 0.0796 - val_accuracy: 0.9755\n",
      "Epoch 709/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1210 - accuracy: 0.9595 - val_loss: 0.0728 - val_accuracy: 0.9790\n",
      "Epoch 710/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9573 - val_loss: 0.0751 - val_accuracy: 0.9755\n",
      "Epoch 711/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1208 - accuracy: 0.9604 - val_loss: 0.0755 - val_accuracy: 0.9773\n",
      "Epoch 712/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1250 - accuracy: 0.9582 - val_loss: 0.0841 - val_accuracy: 0.9755\n",
      "Epoch 713/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1278 - accuracy: 0.9579 - val_loss: 0.0696 - val_accuracy: 0.9764\n",
      "Epoch 714/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1377 - accuracy: 0.9547 - val_loss: 0.0706 - val_accuracy: 0.9764\n",
      "Epoch 715/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1323 - accuracy: 0.9561 - val_loss: 0.0798 - val_accuracy: 0.9764\n",
      "Epoch 716/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1238 - accuracy: 0.9604 - val_loss: 0.0629 - val_accuracy: 0.9808\n",
      "Epoch 717/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1203 - accuracy: 0.9618 - val_loss: 0.0770 - val_accuracy: 0.9773\n",
      "Epoch 718/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1292 - accuracy: 0.9578 - val_loss: 0.0648 - val_accuracy: 0.9773\n",
      "Epoch 719/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1266 - accuracy: 0.9594 - val_loss: 0.0788 - val_accuracy: 0.9790\n",
      "Epoch 720/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1220 - accuracy: 0.9596 - val_loss: 0.0800 - val_accuracy: 0.9738\n",
      "Epoch 721/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1273 - accuracy: 0.9579 - val_loss: 0.0757 - val_accuracy: 0.9790\n",
      "Epoch 722/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1245 - accuracy: 0.9581 - val_loss: 0.0697 - val_accuracy: 0.9790\n",
      "Epoch 723/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1306 - accuracy: 0.9575 - val_loss: 0.0806 - val_accuracy: 0.9738\n",
      "Epoch 724/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1344 - accuracy: 0.9564 - val_loss: 0.0660 - val_accuracy: 0.9773\n",
      "Epoch 725/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1256 - accuracy: 0.9578 - val_loss: 0.0811 - val_accuracy: 0.9711\n",
      "Epoch 726/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1263 - accuracy: 0.9580 - val_loss: 0.0756 - val_accuracy: 0.9764\n",
      "Epoch 727/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1205 - accuracy: 0.9618 - val_loss: 0.0689 - val_accuracy: 0.9790\n",
      "Epoch 728/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1093 - accuracy: 0.9651 - val_loss: 0.0673 - val_accuracy: 0.9790\n",
      "Epoch 729/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1322 - accuracy: 0.9581 - val_loss: 0.0790 - val_accuracy: 0.9738\n",
      "Epoch 730/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1324 - accuracy: 0.9566 - val_loss: 0.0724 - val_accuracy: 0.9773\n",
      "Epoch 731/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1211 - accuracy: 0.9605 - val_loss: 0.0716 - val_accuracy: 0.9746\n",
      "Epoch 732/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9595 - val_loss: 0.0704 - val_accuracy: 0.9799\n",
      "Epoch 733/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9588 - val_loss: 0.0622 - val_accuracy: 0.9808\n",
      "Epoch 734/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1217 - accuracy: 0.9597 - val_loss: 0.0691 - val_accuracy: 0.9790\n",
      "Epoch 735/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1246 - accuracy: 0.9597 - val_loss: 0.0626 - val_accuracy: 0.9773\n",
      "Epoch 736/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1121 - accuracy: 0.9613 - val_loss: 0.0781 - val_accuracy: 0.9773\n",
      "Epoch 737/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1177 - accuracy: 0.9611 - val_loss: 0.0772 - val_accuracy: 0.9755\n",
      "Epoch 738/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1304 - accuracy: 0.9554 - val_loss: 0.0685 - val_accuracy: 0.9781\n",
      "Epoch 739/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1174 - accuracy: 0.9610 - val_loss: 0.0809 - val_accuracy: 0.9773\n",
      "Epoch 740/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1219 - accuracy: 0.9593 - val_loss: 0.0638 - val_accuracy: 0.9799\n",
      "Epoch 741/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1271 - accuracy: 0.9564 - val_loss: 0.0626 - val_accuracy: 0.9808\n",
      "Epoch 742/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1327 - accuracy: 0.9591 - val_loss: 0.0745 - val_accuracy: 0.9746\n",
      "Epoch 743/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1324 - accuracy: 0.9577 - val_loss: 0.0630 - val_accuracy: 0.9799\n",
      "Epoch 744/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1323 - accuracy: 0.9576 - val_loss: 0.0683 - val_accuracy: 0.9773\n",
      "Epoch 745/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1061 - accuracy: 0.9654 - val_loss: 0.0710 - val_accuracy: 0.9764\n",
      "Epoch 746/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1365 - accuracy: 0.9579 - val_loss: 0.0846 - val_accuracy: 0.9729\n",
      "Epoch 747/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1321 - accuracy: 0.9570 - val_loss: 0.0729 - val_accuracy: 0.9764\n",
      "Epoch 748/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1237 - accuracy: 0.9600 - val_loss: 0.0858 - val_accuracy: 0.9729\n",
      "Epoch 749/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1269 - accuracy: 0.9592 - val_loss: 0.0861 - val_accuracy: 0.9711\n",
      "Epoch 750/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1263 - accuracy: 0.9561 - val_loss: 0.0728 - val_accuracy: 0.9764\n",
      "Epoch 751/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9562 - val_loss: 0.0729 - val_accuracy: 0.9711\n",
      "Epoch 752/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1237 - accuracy: 0.9597 - val_loss: 0.0681 - val_accuracy: 0.9755\n",
      "Epoch 753/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1361 - accuracy: 0.9546 - val_loss: 0.0707 - val_accuracy: 0.9764\n",
      "Epoch 754/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1186 - accuracy: 0.9613 - val_loss: 0.0581 - val_accuracy: 0.9790\n",
      "Epoch 755/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.9602 - val_loss: 0.0691 - val_accuracy: 0.9790\n",
      "Epoch 756/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1310 - accuracy: 0.9569 - val_loss: 0.0698 - val_accuracy: 0.9790\n",
      "Epoch 757/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1179 - accuracy: 0.9593 - val_loss: 0.0756 - val_accuracy: 0.9790\n",
      "Epoch 758/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1253 - accuracy: 0.9606 - val_loss: 0.0720 - val_accuracy: 0.9738\n",
      "Epoch 759/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1158 - accuracy: 0.9627 - val_loss: 0.0758 - val_accuracy: 0.9755\n",
      "Epoch 760/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1282 - accuracy: 0.9595 - val_loss: 0.0621 - val_accuracy: 0.9790\n",
      "Epoch 761/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1350 - accuracy: 0.9544 - val_loss: 0.0746 - val_accuracy: 0.9764\n",
      "Epoch 762/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.9621 - val_loss: 0.0757 - val_accuracy: 0.9746\n",
      "Epoch 763/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1233 - accuracy: 0.9585 - val_loss: 0.0750 - val_accuracy: 0.9764\n",
      "Epoch 764/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1069 - accuracy: 0.9655 - val_loss: 0.0683 - val_accuracy: 0.9764\n",
      "Epoch 765/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1278 - accuracy: 0.9595 - val_loss: 0.0778 - val_accuracy: 0.9729\n",
      "Epoch 766/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1264 - accuracy: 0.9600 - val_loss: 0.0636 - val_accuracy: 0.9843\n",
      "Epoch 767/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1164 - accuracy: 0.9615 - val_loss: 0.0906 - val_accuracy: 0.9703\n",
      "Epoch 768/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1318 - accuracy: 0.9572 - val_loss: 0.0788 - val_accuracy: 0.9773\n",
      "Epoch 769/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.9592 - val_loss: 0.0917 - val_accuracy: 0.9711\n",
      "Epoch 770/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1149 - accuracy: 0.9634 - val_loss: 0.0768 - val_accuracy: 0.9738\n",
      "Epoch 771/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1218 - accuracy: 0.9593 - val_loss: 0.0773 - val_accuracy: 0.9781\n",
      "Epoch 772/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9603 - val_loss: 0.0731 - val_accuracy: 0.9773\n",
      "Epoch 773/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1158 - accuracy: 0.9592 - val_loss: 0.0804 - val_accuracy: 0.9773\n",
      "Epoch 774/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1267 - accuracy: 0.9575 - val_loss: 0.0844 - val_accuracy: 0.9746\n",
      "Epoch 775/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1255 - accuracy: 0.9585 - val_loss: 0.0938 - val_accuracy: 0.9738\n",
      "Epoch 776/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1268 - accuracy: 0.9575 - val_loss: 0.0759 - val_accuracy: 0.9773\n",
      "Epoch 777/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1170 - accuracy: 0.9606 - val_loss: 0.0801 - val_accuracy: 0.9764\n",
      "Epoch 778/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1272 - accuracy: 0.9599 - val_loss: 0.0787 - val_accuracy: 0.9781\n",
      "Epoch 779/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1228 - accuracy: 0.9605 - val_loss: 0.0819 - val_accuracy: 0.9729\n",
      "Epoch 780/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1157 - accuracy: 0.9612 - val_loss: 0.0841 - val_accuracy: 0.9764\n",
      "Epoch 781/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1212 - accuracy: 0.9592 - val_loss: 0.0745 - val_accuracy: 0.9808\n",
      "Epoch 782/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1264 - accuracy: 0.9575 - val_loss: 0.0699 - val_accuracy: 0.9808\n",
      "Epoch 783/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1269 - accuracy: 0.9601 - val_loss: 0.0859 - val_accuracy: 0.9703\n",
      "Epoch 784/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1333 - accuracy: 0.9572 - val_loss: 0.0782 - val_accuracy: 0.9755\n",
      "Epoch 785/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1237 - accuracy: 0.9605 - val_loss: 0.0709 - val_accuracy: 0.9773\n",
      "Epoch 786/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1334 - accuracy: 0.9576 - val_loss: 0.0806 - val_accuracy: 0.9746\n",
      "Epoch 787/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1262 - accuracy: 0.9603 - val_loss: 0.0735 - val_accuracy: 0.9790\n",
      "Epoch 788/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1153 - accuracy: 0.9609 - val_loss: 0.0821 - val_accuracy: 0.9738\n",
      "Epoch 789/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1225 - accuracy: 0.9601 - val_loss: 0.0814 - val_accuracy: 0.9781\n",
      "Epoch 790/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1312 - accuracy: 0.9585 - val_loss: 0.0885 - val_accuracy: 0.9746\n",
      "Epoch 791/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1228 - accuracy: 0.9608 - val_loss: 0.0766 - val_accuracy: 0.9781\n",
      "Epoch 792/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1294 - accuracy: 0.9563 - val_loss: 0.0792 - val_accuracy: 0.9738\n",
      "Epoch 793/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.9586 - val_loss: 0.0853 - val_accuracy: 0.9773\n",
      "Epoch 794/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9601 - val_loss: 0.0869 - val_accuracy: 0.9738\n",
      "Epoch 795/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1215 - accuracy: 0.9593 - val_loss: 0.0949 - val_accuracy: 0.9650\n",
      "Epoch 796/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1351 - accuracy: 0.9556 - val_loss: 0.0817 - val_accuracy: 0.9746\n",
      "Epoch 797/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1277 - accuracy: 0.9581 - val_loss: 0.0772 - val_accuracy: 0.9755\n",
      "Epoch 798/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1381 - accuracy: 0.9559 - val_loss: 0.0753 - val_accuracy: 0.9755\n",
      "Epoch 799/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1275 - accuracy: 0.9579 - val_loss: 0.0717 - val_accuracy: 0.9790\n",
      "Epoch 800/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1185 - accuracy: 0.9614 - val_loss: 0.0704 - val_accuracy: 0.9799\n",
      "Epoch 801/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1098 - accuracy: 0.9635 - val_loss: 0.0735 - val_accuracy: 0.9773\n",
      "Epoch 802/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1249 - accuracy: 0.9587 - val_loss: 0.0804 - val_accuracy: 0.9738\n",
      "Epoch 803/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1119 - accuracy: 0.9637 - val_loss: 0.0690 - val_accuracy: 0.9773\n",
      "Epoch 804/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9597 - val_loss: 0.0711 - val_accuracy: 0.9781\n",
      "Epoch 805/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1297 - accuracy: 0.9576 - val_loss: 0.0794 - val_accuracy: 0.9755\n",
      "Epoch 806/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1107 - accuracy: 0.9630 - val_loss: 0.0773 - val_accuracy: 0.9738\n",
      "Epoch 807/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1111 - accuracy: 0.9632 - val_loss: 0.0621 - val_accuracy: 0.9773\n",
      "Epoch 808/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1165 - accuracy: 0.9586 - val_loss: 0.0804 - val_accuracy: 0.9764\n",
      "Epoch 809/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1128 - accuracy: 0.9607 - val_loss: 0.0786 - val_accuracy: 0.9773\n",
      "Epoch 810/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1222 - accuracy: 0.9606 - val_loss: 0.0761 - val_accuracy: 0.9781\n",
      "Epoch 811/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1278 - accuracy: 0.9586 - val_loss: 0.0850 - val_accuracy: 0.9755\n",
      "Epoch 812/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1137 - accuracy: 0.9626 - val_loss: 0.0750 - val_accuracy: 0.9790\n",
      "Epoch 813/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1109 - accuracy: 0.9624 - val_loss: 0.0862 - val_accuracy: 0.9764\n",
      "Epoch 814/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1114 - accuracy: 0.9637 - val_loss: 0.0816 - val_accuracy: 0.9764\n",
      "Epoch 815/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1310 - accuracy: 0.9575 - val_loss: 0.0702 - val_accuracy: 0.9773\n",
      "Epoch 816/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1265 - accuracy: 0.9584 - val_loss: 0.0632 - val_accuracy: 0.9825\n",
      "Epoch 817/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1194 - accuracy: 0.9626 - val_loss: 0.0708 - val_accuracy: 0.9781\n",
      "Epoch 818/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1057 - accuracy: 0.9651 - val_loss: 0.0663 - val_accuracy: 0.9781\n",
      "Epoch 819/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1255 - accuracy: 0.9597 - val_loss: 0.0762 - val_accuracy: 0.9781\n",
      "Epoch 820/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1138 - accuracy: 0.9595 - val_loss: 0.0663 - val_accuracy: 0.9790\n",
      "Epoch 821/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1067 - accuracy: 0.9655 - val_loss: 0.0831 - val_accuracy: 0.9738\n",
      "Epoch 822/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.9609 - val_loss: 0.0765 - val_accuracy: 0.9746\n",
      "Epoch 823/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1220 - accuracy: 0.9608 - val_loss: 0.0762 - val_accuracy: 0.9781\n",
      "Epoch 824/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1261 - accuracy: 0.9575 - val_loss: 0.0668 - val_accuracy: 0.9790\n",
      "Epoch 825/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1162 - accuracy: 0.9612 - val_loss: 0.0847 - val_accuracy: 0.9773\n",
      "Epoch 826/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.9617 - val_loss: 0.0863 - val_accuracy: 0.9746\n",
      "Epoch 827/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9598 - val_loss: 0.0860 - val_accuracy: 0.9773\n",
      "Epoch 828/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1242 - accuracy: 0.9584 - val_loss: 0.0809 - val_accuracy: 0.9755\n",
      "Epoch 829/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1261 - accuracy: 0.9609 - val_loss: 0.0759 - val_accuracy: 0.9799\n",
      "Epoch 830/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1268 - accuracy: 0.9598 - val_loss: 0.0740 - val_accuracy: 0.9799\n",
      "Epoch 831/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1205 - accuracy: 0.9590 - val_loss: 0.0855 - val_accuracy: 0.9703\n",
      "Epoch 832/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1155 - accuracy: 0.9632 - val_loss: 0.0799 - val_accuracy: 0.9781\n",
      "Epoch 833/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1139 - accuracy: 0.9641 - val_loss: 0.0852 - val_accuracy: 0.9746\n",
      "Epoch 834/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1165 - accuracy: 0.9621 - val_loss: 0.0749 - val_accuracy: 0.9790\n",
      "Epoch 835/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1266 - accuracy: 0.9601 - val_loss: 0.0773 - val_accuracy: 0.9738\n",
      "Epoch 836/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1147 - accuracy: 0.9626 - val_loss: 0.0690 - val_accuracy: 0.9808\n",
      "Epoch 837/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1196 - accuracy: 0.9616 - val_loss: 0.0670 - val_accuracy: 0.9808\n",
      "Epoch 838/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1144 - accuracy: 0.9613 - val_loss: 0.0883 - val_accuracy: 0.9781\n",
      "Epoch 839/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1174 - accuracy: 0.9623 - val_loss: 0.0881 - val_accuracy: 0.9729\n",
      "Epoch 840/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1205 - accuracy: 0.9610 - val_loss: 0.0751 - val_accuracy: 0.9746\n",
      "Epoch 841/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1162 - accuracy: 0.9610 - val_loss: 0.0760 - val_accuracy: 0.9755\n",
      "Epoch 842/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1215 - accuracy: 0.9619 - val_loss: 0.0765 - val_accuracy: 0.9816\n",
      "Epoch 843/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1328 - accuracy: 0.9573 - val_loss: 0.0604 - val_accuracy: 0.9790\n",
      "Epoch 844/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1071 - accuracy: 0.9642 - val_loss: 0.0756 - val_accuracy: 0.9781\n",
      "Epoch 845/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1102 - accuracy: 0.9633 - val_loss: 0.0739 - val_accuracy: 0.9799\n",
      "Epoch 846/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1147 - accuracy: 0.9619 - val_loss: 0.0651 - val_accuracy: 0.9764\n",
      "Epoch 847/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1232 - accuracy: 0.9593 - val_loss: 0.0783 - val_accuracy: 0.9755\n",
      "Epoch 848/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1165 - accuracy: 0.9621 - val_loss: 0.0707 - val_accuracy: 0.9764\n",
      "Epoch 849/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1213 - accuracy: 0.9612 - val_loss: 0.0674 - val_accuracy: 0.9746\n",
      "Epoch 850/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1325 - accuracy: 0.9578 - val_loss: 0.0743 - val_accuracy: 0.9755\n",
      "Epoch 851/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1170 - accuracy: 0.9610 - val_loss: 0.0697 - val_accuracy: 0.9799\n",
      "Epoch 852/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1201 - accuracy: 0.9609 - val_loss: 0.0738 - val_accuracy: 0.9816\n",
      "Epoch 853/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1267 - accuracy: 0.9580 - val_loss: 0.0743 - val_accuracy: 0.9764\n",
      "Epoch 854/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1336 - accuracy: 0.9567 - val_loss: 0.0824 - val_accuracy: 0.9799\n",
      "Epoch 855/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1207 - accuracy: 0.9605 - val_loss: 0.0637 - val_accuracy: 0.9799\n",
      "Epoch 856/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1217 - accuracy: 0.9617 - val_loss: 0.0690 - val_accuracy: 0.9799\n",
      "Epoch 857/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1181 - accuracy: 0.9626 - val_loss: 0.0752 - val_accuracy: 0.9781\n",
      "Epoch 858/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1201 - accuracy: 0.9603 - val_loss: 0.0587 - val_accuracy: 0.9808\n",
      "Epoch 859/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1129 - accuracy: 0.9627 - val_loss: 0.0589 - val_accuracy: 0.9790\n",
      "Epoch 860/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1175 - accuracy: 0.9611 - val_loss: 0.0674 - val_accuracy: 0.9746\n",
      "Epoch 861/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1345 - accuracy: 0.9555 - val_loss: 0.0592 - val_accuracy: 0.9808\n",
      "Epoch 862/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1118 - accuracy: 0.9619 - val_loss: 0.0783 - val_accuracy: 0.9738\n",
      "Epoch 863/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1128 - accuracy: 0.9625 - val_loss: 0.0633 - val_accuracy: 0.9808\n",
      "Epoch 864/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1219 - accuracy: 0.9603 - val_loss: 0.0747 - val_accuracy: 0.9729\n",
      "Epoch 865/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1258 - accuracy: 0.9614 - val_loss: 0.0694 - val_accuracy: 0.9816\n",
      "Epoch 866/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9606 - val_loss: 0.0611 - val_accuracy: 0.9843\n",
      "Epoch 867/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1112 - accuracy: 0.9643 - val_loss: 0.0618 - val_accuracy: 0.9808\n",
      "Epoch 868/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1113 - accuracy: 0.9639 - val_loss: 0.0762 - val_accuracy: 0.9773\n",
      "Epoch 869/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1222 - accuracy: 0.9593 - val_loss: 0.0725 - val_accuracy: 0.9764\n",
      "Epoch 870/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1180 - accuracy: 0.9623 - val_loss: 0.0752 - val_accuracy: 0.9755\n",
      "Epoch 871/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1321 - accuracy: 0.9568 - val_loss: 0.0773 - val_accuracy: 0.9746\n",
      "Epoch 872/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1345 - accuracy: 0.9573 - val_loss: 0.0687 - val_accuracy: 0.9816\n",
      "Epoch 873/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.9614 - val_loss: 0.0602 - val_accuracy: 0.9834\n",
      "Epoch 874/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1286 - accuracy: 0.9594 - val_loss: 0.0644 - val_accuracy: 0.9816\n",
      "Epoch 875/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1226 - accuracy: 0.9612 - val_loss: 0.0719 - val_accuracy: 0.9764\n",
      "Epoch 876/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1236 - accuracy: 0.9608 - val_loss: 0.0646 - val_accuracy: 0.9790\n",
      "Epoch 877/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1246 - accuracy: 0.9623 - val_loss: 0.0733 - val_accuracy: 0.9799\n",
      "Epoch 878/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1249 - accuracy: 0.9585 - val_loss: 0.0863 - val_accuracy: 0.9711\n",
      "Epoch 879/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1037 - accuracy: 0.9666 - val_loss: 0.0762 - val_accuracy: 0.9773\n",
      "Epoch 880/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.9546 - val_loss: 0.0722 - val_accuracy: 0.9755\n",
      "Epoch 881/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1256 - accuracy: 0.9591 - val_loss: 0.0621 - val_accuracy: 0.9816\n",
      "Epoch 882/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1163 - accuracy: 0.9626 - val_loss: 0.0626 - val_accuracy: 0.9808\n",
      "Epoch 883/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1213 - accuracy: 0.9609 - val_loss: 0.0655 - val_accuracy: 0.9764\n",
      "Epoch 884/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1217 - accuracy: 0.9596 - val_loss: 0.0754 - val_accuracy: 0.9729\n",
      "Epoch 885/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1147 - accuracy: 0.9616 - val_loss: 0.0830 - val_accuracy: 0.9755\n",
      "Epoch 886/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1128 - accuracy: 0.9641 - val_loss: 0.0655 - val_accuracy: 0.9825\n",
      "Epoch 887/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1176 - accuracy: 0.9626 - val_loss: 0.0729 - val_accuracy: 0.9764\n",
      "Epoch 888/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1149 - accuracy: 0.9624 - val_loss: 0.0791 - val_accuracy: 0.9781\n",
      "Epoch 889/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1081 - accuracy: 0.9647 - val_loss: 0.0711 - val_accuracy: 0.9799\n",
      "Epoch 890/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1246 - accuracy: 0.9591 - val_loss: 0.0630 - val_accuracy: 0.9808\n",
      "Epoch 891/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1305 - accuracy: 0.9566 - val_loss: 0.0666 - val_accuracy: 0.9816\n",
      "Epoch 892/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1176 - accuracy: 0.9619 - val_loss: 0.0678 - val_accuracy: 0.9790\n",
      "Epoch 893/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9610 - val_loss: 0.0657 - val_accuracy: 0.9781\n",
      "Epoch 894/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1045 - accuracy: 0.9646 - val_loss: 0.0620 - val_accuracy: 0.9825\n",
      "Epoch 895/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1218 - accuracy: 0.9601 - val_loss: 0.0669 - val_accuracy: 0.9816\n",
      "Epoch 896/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1131 - accuracy: 0.9635 - val_loss: 0.0692 - val_accuracy: 0.9773\n",
      "Epoch 897/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1052 - accuracy: 0.9664 - val_loss: 0.0642 - val_accuracy: 0.9808\n",
      "Epoch 898/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1080 - accuracy: 0.9650 - val_loss: 0.0797 - val_accuracy: 0.9790\n",
      "Epoch 899/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1221 - accuracy: 0.9626 - val_loss: 0.0574 - val_accuracy: 0.9825\n",
      "Epoch 900/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1155 - accuracy: 0.9644 - val_loss: 0.0715 - val_accuracy: 0.9790\n",
      "Epoch 901/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.9600 - val_loss: 0.0811 - val_accuracy: 0.9746\n",
      "Epoch 902/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1133 - accuracy: 0.9642 - val_loss: 0.0750 - val_accuracy: 0.9790\n",
      "Epoch 903/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1226 - accuracy: 0.9601 - val_loss: 0.0755 - val_accuracy: 0.9773\n",
      "Epoch 904/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1107 - accuracy: 0.9655 - val_loss: 0.0677 - val_accuracy: 0.9834\n",
      "Epoch 905/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1262 - accuracy: 0.9575 - val_loss: 0.0768 - val_accuracy: 0.9781\n",
      "Epoch 906/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1072 - accuracy: 0.9645 - val_loss: 0.0761 - val_accuracy: 0.9746\n",
      "Epoch 907/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1258 - accuracy: 0.9600 - val_loss: 0.0732 - val_accuracy: 0.9808\n",
      "Epoch 908/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1397 - accuracy: 0.9570 - val_loss: 0.0753 - val_accuracy: 0.9746\n",
      "Epoch 909/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1146 - accuracy: 0.9637 - val_loss: 0.0715 - val_accuracy: 0.9781\n",
      "Epoch 910/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1194 - accuracy: 0.9612 - val_loss: 0.0860 - val_accuracy: 0.9799\n",
      "Epoch 911/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1175 - accuracy: 0.9624 - val_loss: 0.0768 - val_accuracy: 0.9773\n",
      "Epoch 912/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1064 - accuracy: 0.9671 - val_loss: 0.0726 - val_accuracy: 0.9790\n",
      "Epoch 913/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1135 - accuracy: 0.9650 - val_loss: 0.0705 - val_accuracy: 0.9790\n",
      "Epoch 914/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1079 - accuracy: 0.9655 - val_loss: 0.0792 - val_accuracy: 0.9790\n",
      "Epoch 915/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1121 - accuracy: 0.9639 - val_loss: 0.0654 - val_accuracy: 0.9781\n",
      "Epoch 916/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1115 - accuracy: 0.9628 - val_loss: 0.0809 - val_accuracy: 0.9790\n",
      "Epoch 917/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1255 - accuracy: 0.9611 - val_loss: 0.0830 - val_accuracy: 0.9790\n",
      "Epoch 918/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1153 - accuracy: 0.9628 - val_loss: 0.0735 - val_accuracy: 0.9781\n",
      "Epoch 919/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1283 - accuracy: 0.9583 - val_loss: 0.0717 - val_accuracy: 0.9746\n",
      "Epoch 920/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1162 - accuracy: 0.9606 - val_loss: 0.0635 - val_accuracy: 0.9764\n",
      "Epoch 921/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1242 - accuracy: 0.9591 - val_loss: 0.0803 - val_accuracy: 0.9738\n",
      "Epoch 922/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1221 - accuracy: 0.9588 - val_loss: 0.0769 - val_accuracy: 0.9781\n",
      "Epoch 923/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.9606 - val_loss: 0.0817 - val_accuracy: 0.9790\n",
      "Epoch 924/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1240 - accuracy: 0.9592 - val_loss: 0.0718 - val_accuracy: 0.9799\n",
      "Epoch 925/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1168 - accuracy: 0.9629 - val_loss: 0.0659 - val_accuracy: 0.9808\n",
      "Epoch 926/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1140 - accuracy: 0.9662 - val_loss: 0.0618 - val_accuracy: 0.9816\n",
      "Epoch 927/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1031 - accuracy: 0.9666 - val_loss: 0.0670 - val_accuracy: 0.9790\n",
      "Epoch 928/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1142 - accuracy: 0.9649 - val_loss: 0.0693 - val_accuracy: 0.9799\n",
      "Epoch 929/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1351 - accuracy: 0.9558 - val_loss: 0.0787 - val_accuracy: 0.9746\n",
      "Epoch 930/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1277 - accuracy: 0.9595 - val_loss: 0.0780 - val_accuracy: 0.9781\n",
      "Epoch 931/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.9599 - val_loss: 0.0732 - val_accuracy: 0.9816\n",
      "Epoch 932/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1107 - accuracy: 0.9633 - val_loss: 0.0715 - val_accuracy: 0.9808\n",
      "Epoch 933/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1145 - accuracy: 0.9628 - val_loss: 0.0751 - val_accuracy: 0.9746\n",
      "Epoch 934/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.9626 - val_loss: 0.0759 - val_accuracy: 0.9799\n",
      "Epoch 935/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1280 - accuracy: 0.9601 - val_loss: 0.0831 - val_accuracy: 0.9746\n",
      "Epoch 936/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1035 - accuracy: 0.9660 - val_loss: 0.0791 - val_accuracy: 0.9773\n",
      "Epoch 937/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1114 - accuracy: 0.9627 - val_loss: 0.0799 - val_accuracy: 0.9781\n",
      "Epoch 938/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1239 - accuracy: 0.9601 - val_loss: 0.0738 - val_accuracy: 0.9781\n",
      "Epoch 939/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1219 - accuracy: 0.9595 - val_loss: 0.0814 - val_accuracy: 0.9781\n",
      "Epoch 940/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1167 - accuracy: 0.9620 - val_loss: 0.0877 - val_accuracy: 0.9746\n",
      "Epoch 941/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1134 - accuracy: 0.9640 - val_loss: 0.0772 - val_accuracy: 0.9799\n",
      "Epoch 942/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1106 - accuracy: 0.9623 - val_loss: 0.0896 - val_accuracy: 0.9764\n",
      "Epoch 943/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1092 - accuracy: 0.9636 - val_loss: 0.0788 - val_accuracy: 0.9790\n",
      "Epoch 944/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1109 - accuracy: 0.9640 - val_loss: 0.0703 - val_accuracy: 0.9816\n",
      "Epoch 945/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1102 - accuracy: 0.9655 - val_loss: 0.0768 - val_accuracy: 0.9755\n",
      "Epoch 946/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1125 - accuracy: 0.9626 - val_loss: 0.0793 - val_accuracy: 0.9773\n",
      "Epoch 947/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1185 - accuracy: 0.9624 - val_loss: 0.0846 - val_accuracy: 0.9790\n",
      "Epoch 948/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1242 - accuracy: 0.9612 - val_loss: 0.0687 - val_accuracy: 0.9834\n",
      "Epoch 949/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1151 - accuracy: 0.9618 - val_loss: 0.0823 - val_accuracy: 0.9755\n",
      "Epoch 950/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1175 - accuracy: 0.9643 - val_loss: 0.0710 - val_accuracy: 0.9755\n",
      "Epoch 951/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1183 - accuracy: 0.9615 - val_loss: 0.0683 - val_accuracy: 0.9799\n",
      "Epoch 952/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1226 - accuracy: 0.9614 - val_loss: 0.0858 - val_accuracy: 0.9781\n",
      "Epoch 953/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1093 - accuracy: 0.9646 - val_loss: 0.0918 - val_accuracy: 0.9738\n",
      "Epoch 954/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1130 - accuracy: 0.9644 - val_loss: 0.0704 - val_accuracy: 0.9808\n",
      "Epoch 955/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9632 - val_loss: 0.0860 - val_accuracy: 0.9834\n",
      "Epoch 956/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.9592 - val_loss: 0.0840 - val_accuracy: 0.9746\n",
      "Epoch 957/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.9595 - val_loss: 0.0843 - val_accuracy: 0.9773\n",
      "Epoch 958/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1430 - accuracy: 0.9558 - val_loss: 0.0858 - val_accuracy: 0.9738\n",
      "Epoch 959/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1045 - accuracy: 0.9662 - val_loss: 0.0821 - val_accuracy: 0.9773\n",
      "Epoch 960/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1226 - accuracy: 0.9603 - val_loss: 0.0819 - val_accuracy: 0.9781\n",
      "Epoch 961/1000\n",
      "161/161 [==============================] - 2s 10ms/step - loss: 0.1135 - accuracy: 0.9643 - val_loss: 0.0774 - val_accuracy: 0.9773\n",
      "Epoch 962/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1015 - accuracy: 0.9659 - val_loss: 0.0897 - val_accuracy: 0.9746\n",
      "Epoch 963/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1099 - accuracy: 0.9653 - val_loss: 0.0810 - val_accuracy: 0.9755\n",
      "Epoch 964/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1042 - accuracy: 0.9641 - val_loss: 0.0731 - val_accuracy: 0.9808\n",
      "Epoch 965/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1213 - accuracy: 0.9632 - val_loss: 0.0803 - val_accuracy: 0.9764\n",
      "Epoch 966/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1255 - accuracy: 0.9614 - val_loss: 0.0665 - val_accuracy: 0.9825\n",
      "Epoch 967/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1208 - accuracy: 0.9618 - val_loss: 0.0794 - val_accuracy: 0.9790\n",
      "Epoch 968/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1092 - accuracy: 0.9656 - val_loss: 0.0722 - val_accuracy: 0.9808\n",
      "Epoch 969/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1087 - accuracy: 0.9635 - val_loss: 0.0719 - val_accuracy: 0.9764\n",
      "Epoch 970/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1060 - accuracy: 0.9646 - val_loss: 0.0759 - val_accuracy: 0.9764\n",
      "Epoch 971/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1163 - accuracy: 0.9638 - val_loss: 0.0644 - val_accuracy: 0.9781\n",
      "Epoch 972/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.9639 - val_loss: 0.0625 - val_accuracy: 0.9860\n",
      "Epoch 973/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1125 - accuracy: 0.9640 - val_loss: 0.0654 - val_accuracy: 0.9781\n",
      "Epoch 974/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1145 - accuracy: 0.9611 - val_loss: 0.0731 - val_accuracy: 0.9781\n",
      "Epoch 975/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1172 - accuracy: 0.9616 - val_loss: 0.0815 - val_accuracy: 0.9764\n",
      "Epoch 976/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1095 - accuracy: 0.9642 - val_loss: 0.0898 - val_accuracy: 0.9781\n",
      "Epoch 977/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1285 - accuracy: 0.9576 - val_loss: 0.0729 - val_accuracy: 0.9746\n",
      "Epoch 978/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1134 - accuracy: 0.9612 - val_loss: 0.0728 - val_accuracy: 0.9781\n",
      "Epoch 979/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1138 - accuracy: 0.9638 - val_loss: 0.0793 - val_accuracy: 0.9746\n",
      "Epoch 980/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1003 - accuracy: 0.9670 - val_loss: 0.0753 - val_accuracy: 0.9816\n",
      "Epoch 981/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1166 - accuracy: 0.9632 - val_loss: 0.0822 - val_accuracy: 0.9790\n",
      "Epoch 982/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1108 - accuracy: 0.9670 - val_loss: 0.0794 - val_accuracy: 0.9808\n",
      "Epoch 983/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1098 - accuracy: 0.9665 - val_loss: 0.0809 - val_accuracy: 0.9816\n",
      "Epoch 984/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1200 - accuracy: 0.9640 - val_loss: 0.0842 - val_accuracy: 0.9773\n",
      "Epoch 985/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1045 - accuracy: 0.9663 - val_loss: 0.0793 - val_accuracy: 0.9755\n",
      "Epoch 986/1000\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.1276 - accuracy: 0.9584 - val_loss: 0.0896 - val_accuracy: 0.9764\n",
      "Epoch 987/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1202 - accuracy: 0.9603 - val_loss: 0.0798 - val_accuracy: 0.9755\n",
      "Epoch 988/1000\n",
      "161/161 [==============================] - 1s 9ms/step - loss: 0.1233 - accuracy: 0.9596 - val_loss: 0.0823 - val_accuracy: 0.9790\n",
      "Epoch 989/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.9605 - val_loss: 0.0781 - val_accuracy: 0.9790\n",
      "Epoch 990/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1151 - accuracy: 0.9635 - val_loss: 0.0696 - val_accuracy: 0.9790\n",
      "Epoch 991/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1193 - accuracy: 0.9627 - val_loss: 0.0667 - val_accuracy: 0.9816\n",
      "Epoch 992/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1137 - accuracy: 0.9637 - val_loss: 0.0753 - val_accuracy: 0.9790\n",
      "Epoch 993/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1187 - accuracy: 0.9628 - val_loss: 0.0735 - val_accuracy: 0.9781\n",
      "Epoch 994/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1159 - accuracy: 0.9632 - val_loss: 0.0696 - val_accuracy: 0.9790\n",
      "Epoch 995/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1169 - accuracy: 0.9621 - val_loss: 0.0866 - val_accuracy: 0.9755\n",
      "Epoch 996/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1171 - accuracy: 0.9613 - val_loss: 0.0736 - val_accuracy: 0.9781\n",
      "Epoch 997/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1184 - accuracy: 0.9620 - val_loss: 0.0825 - val_accuracy: 0.9781\n",
      "Epoch 998/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1270 - accuracy: 0.9582 - val_loss: 0.0790 - val_accuracy: 0.9746\n",
      "Epoch 999/1000\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1227 - accuracy: 0.9610 - val_loss: 0.0713 - val_accuracy: 0.9799\n",
      "Epoch 1000/1000\n",
      "161/161 [==============================] - 1s 8ms/step - loss: 0.1107 - accuracy: 0.9647 - val_loss: 0.0773 - val_accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "class customcallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get(\"loss\") < 0.1 and logs.get(\"val_loss\") < 0.1:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64,\n",
    "                    callbacks=[customcallback()],\n",
    "                    epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09988056868314743, 0.9716535210609436]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpursrz5af\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpursrz5af\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 247KB\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "print('Model size: %dKB' % (len(tflite_model) / 1024))\n",
    "\n",
    "with open('../Trainer/model/pose_classifier.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
